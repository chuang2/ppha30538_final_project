---
title: "30538 Final Project: Reproducible Research"
author: "Peter Ganong and Maggie Shi" 
date: "today"
format: pdf
execute:
  eval: false
  echo: false
---

# Project Description and Instructions
The goal of this project is to showcase your knowledge of Python by applying it to a research project about a policy topic you are interested in. You will be graded on coding, writeup, and an in-class presentation.

You may work on this project alone, or in groups of up to three students. All groups must be formed declared in the Canvas proposal before any work is done - it is not possible to join one after. 

It is required that you use GitHub, and we may use your past commits to understand your thought process for partial credit. If you working in a group, note that as we are grading we will be looking for multiple commits per individual throughout the project. The division of labor should be approximately evenly across both individuals. While we will lean toward giving the same grade for all group members, it is possible that individuals may receive different grades based on the commit history.

If you choose to form a group, we recommend that you do so with other students in your section. You are allowed to have a group member from another section, but all group members must be available to attend all the group members' lecture sessions. If you are not present when your project is presented, you will not receive credit for the presentation.


# Grading 
## Coding (70%)
The code for the project should have the following components:

1. Data wrangling (25%)
    * You must use a minimum of *two* datasets. 
    * All processing of the data should be handled by your `.qmd` code, including all merging and reshaping. 

```{python}
# General
import pandas as pd
import numpy as np
from us import states

# Visualization 
import altair as alt

# Geospatial data handling
import geopandas as gpd

# shiny framework
from shiny import App, ui, render
```

```{python}
#Importing the data - AmeriCorps 2021 CEV 
#Source: https://data.americorps.gov/dataset/2021-CEV-Data-Current-Population-Survey-Civic-Enga/rgh8-g2uc/about_data
#Will need to include google drive/dropbox link since > 300MB

#cev_2021_raw = pd.read_csv("/Users/charleshuang/Documents/GitHub/student30538/problem_sets/final_project/data/2021_CEV__Current_Population_Survey_Civic_Engagement_and_Volunteering_Supplement_20241031.csv", encoding = 'utf-8')

#vcl_supplement_raw = pd.read_csv("/Users/charleshuang/Documents/GitHub/student30538/problem_sets/final_project/data/sep21pub.csv")

cev_2021_raw = pd.read_csv("/Users/justinesilverstein/Desktop/ppha30538_final_project/2021_CEV_Data__Current_Population_Survey_Civic_Engagement_and_Volunteering_Supplement_20241201.csv", encoding = 'utf-8')

vcl_supplement_raw = pd.read_csv("/Users/justinesilverstein/Desktop/ppha30538_final_project/sep21pub.csv")
```

Most relevant variables to focus on:

Frequency and Type of Volunteering:
PES16: Did the respondent spend any time volunteering for any organization in the past 12 months?
PES16D: Frequency of volunteering (e.g., basically every day, a few times a week).
PTS16E: Approximate hours spent volunteering.
Political Engagement:
PES2: How often the respondent discussed political, societal, or local issues with friends or family.
PES5: How often these discussions occurred with neighbors.
PES13: Contact or visits to a public official to express opinions.
PES14: Boycotting or buying products based on political values or business practices.
Civic Participation and Group Membership:
PES15: Belonging to groups, organizations, or associations in the past 12 months.
Neighbor and Community Interaction:
PES7: Participation in activities to improve their neighborhood or community.
Voting Behavior:
PES11: Whether the respondent voted in the last local elections.
Social Media and News Consumption:
PES9: Posting views about political, societal, or local issues on the internet or social media.
PES10: Frequency of consuming news related to political or societal issues.

Basic Demographics
Age: PRTAGE (Person's age)
Gender: PESEX (Sex of the respondent)
Race/Ethnicity: PTDTRACE (Detailed race and Hispanic origin)
Marital Status: PEMARITL (Marital status of the respondent)
Household Composition: HRNUMHOU (Number of persons in the household)

Potential Confounding Variables
Income: HEFAMINC (Household family income level)
Education: PEEDUCA (Highest level of school completed)
Urban/Rural Status: GTMETSTA (Metropolitan or non-metropolitan status)
Community Involvement: PES7 (Participation in neighborhood or community activities)
Social Media Use: PES9 (Posting views about political, societal, or local issues on the internet or social media)

This code will filter out the 400+ variables in the dataset to only the relevant ones.

First we need to merge the two datasets:

```{python}
vcl_supplement_raw.columns = vcl_supplement_raw.columns.str.lower()

#I found out the data type is int64 for one df and object for the other

cev_2021_raw = cev_2021_raw.astype(str)
vcl_supplement_raw = vcl_supplement_raw.astype(str)

#This finds all the variables in common between the two for a merge
common_keys = list(set(vcl_supplement_raw.columns).intersection(set(cev_2021_raw.columns)))



cev_all_2021 = pd.merge(cev_2021_raw, vcl_supplement_raw, on=common_keys, how="outer")

cev_all_2021.head(5)

#Note: Each row is a person- multiple people in the same household can have same household ID, so should not filter by unique

# We can use a config.py file to keep this readable. Full details are in the config.py file
``` 

```{python}
from config import selected_variables, rename_mapping


# selected_variables = ['hrhhid', 'hrhhid2', etc.]
# This chooses the variables we want from the merged raw data

# rename_mapping = "hrhhid": "Household_ID", "hrhhid2": "Household_ID_2", etc.
# Renaming the variables for clarity


cev_all_2021_filter = cev_all_2021[selected_variables].copy()
#copy avoids potentially modifying original dataframe

cev_all_2021_filter.rename(columns=rename_mapping, inplace=True)

#Debugging: removing duplicate column(s)
cev_all_2021_filter = cev_all_2021_filter.loc[:, ~cev_all_2021_filter.columns.duplicated()]
```


The data is a mix of numeric code and qualitative input, so we need to keep the qualitative input while mapping only numeric codes. The qualitative input is outside of the data dictionary, so it won't get picked up by any mapping functions and will be transmuted into NaN data. We will make a function that identifies all the values in the data that aren't picked up by our data dictionaries in config.py.

For example, here's a sample from config.py:

Renaming pes16 - Volunteered Past Year
In the past 12 months, did [you/[NAME]] spend any time volunteering for any organization or association?

pes16_dict = {
    '1': 'Yes',
    '2': 'No',
    '-1': 'Not in Universe',
    '-3': 'Refusal',
    '-2': 'Do Not Know',
    '-9': 'No Answer',
    '.u': 'No Answer',
    '.r': 'Refusal',
    '.n': 'Not in Universe',
    '.d': 'Do Not Know'
}

If there are some entries in this column that are already coded "Yes" or "No", our existing mapping won't account for them and will turn them into NANs. That's not desirable. We want to catch those and account for them.

```{python}
#For testing purposes, delete later
cev_pre_clean_test = cev_all_2021_filter.copy()


# Attribution: Asked ChatGPT "why isn't config.py updating when I add dictionaries to it; ChatGPT suggested using importlib reload"
# Import and reload config
import importlib
import config
importlib.reload(config)
from config import *

# Replace FIPS codes with states

fips_to_state = {int(state.fips): state.abbr for state in states.STATES}

cev_all_2021_filter['US State'] = pd.to_numeric(
    cev_all_2021_filter['US State'], errors='coerce')

cev_all_2021_filter['US State'] = cev_all_2021_filter['US State'].map(
    fips_to_state)

# Replace "Volunteered Past Year" data (pes16)
cev_all_2021_filter['Volunteered_Past_Year'] = cev_all_2021_filter['Volunteered_Past_Year'].map(
    pes16_dict)

# Replace "Volunteering Frequency" (pes16d)
cev_all_2021_filter['Volunteering_Frequency'] = cev_all_2021_filter['Volunteering_Frequency'].map(
    pes16d_dict)

# Replace "Hours Spent Volunteering" (pts16e)
cev_all_2021_filter['Hours_Spent_Volunteering'] = cev_all_2021_filter['Hours_Spent_Volunteering'].map(
    pts16e_dict)

# Replace "Discussed Issues with Friends/Family" data (pes2)
cev_all_2021_filter['Discussed_Issues_With_Friends_Family'] = cev_all_2021_filter['Discussed_Issues_With_Friends_Family'].map(
    pes2_dict)

# Replace "Discussed Issues with Neighbors" data (pes5)
cev_all_2021_filter['Discussed_Issues_With_Neighbors'] = cev_all_2021_filter['Discussed_Issues_With_Neighbors'].map(
    pes5_dict)

# Replace "Contacted Public Official" data (pes13)
cev_all_2021_filter['Contacted_Public_Official'] = cev_all_2021_filter['Contacted_Public_Official'].map(
    pes13_dict)

# Replace "Boycott Based on Values" data (pes14)
cev_all_2021_filter['Boycott_Based_On_Values'] = cev_all_2021_filter['Boycott_Based_On_Values'].map(
    pes14_dict)

# Replace "Belonged to Groups" data (pes15)
cev_all_2021_filter['Belonged_To_Groups'] = cev_all_2021_filter['Belonged_To_Groups'].map(
    pes15_dict)


# Replace "Community Improvement Activities" data (pes7)
cev_all_2021_filter['Community_Improvement_Activities'] = cev_all_2021_filter['Community_Improvement_Activities'].map(
    pes7_dict)

# Replace "Voted in Local Election" data (pes11)
cev_all_2021_filter['Voted_In_Local_Election'] = cev_all_2021_filter['Voted_In_Local_Election'].map(
    pes11_dict)

# Replace "Posted Views on Social Media" data (pes9)
cev_all_2021_filter['Posted_Views_On_Social_Media'] = cev_all_2021_filter['Posted_Views_On_Social_Media'].map(
    pes9_dict)

# Replace "Frequency of News Consumption" data (pes10)
cev_all_2021_filter['Frequency_Of_News_Consumption'] = cev_all_2021_filter['Frequency_Of_News_Consumption'].map(
    pes10_dict)

# Replace "Age" data (prtage)
cev_all_2021_filter['Age'] = cev_all_2021_filter['Age'].map(prtage_dict)

# Replace "Gender" data (pesex)
cev_all_2021_filter['Gender'] = cev_all_2021_filter['Gender'].map(pesex_dict)

# Replace "Race/Ethnicity" data (ptdtrace)
cev_all_2021_filter['Race_Ethnicity'] = cev_all_2021_filter['Race_Ethnicity'].map(
    ptdtrace_dict)

# Replace "Marital Status" data (pemaritl)
cev_all_2021_filter['Marital_Status'] = cev_all_2021_filter['Marital_Status'].map(
    pemaritl_dict)

# Replace "Household Size" data (hrnumhou)
cev_all_2021_filter['Household_Size'] = cev_all_2021_filter['Household_Size'].map(
    hrnumhou_dict)

# Replace "Family Income Level" data (hefaminc)
cev_all_2021_filter['Family_Income_Level'] = cev_all_2021_filter['Family_Income_Level'].map(
    hefaminc_dict)

# Replace "Education Level" data (peeduca_dict)
cev_all_2021_filter['Education_Level'] = cev_all_2021_filter['Education_Level'].map(
    peeduca_dict)

# Replace "Urban Rural Status" data (gtmetsta_dict)
cev_all_2021_filter['Urban_Rural_Status'] = cev_all_2021_filter['Urban_Rural_Status'].map(
    gtmetsta_dict)

```

Lastly, export the cleaned data as a csv for plotting purposes

```{python}
import os
from pathlib import Path

shiny_data_path = Path("shiny-app/basic-app/data")

# Create directory if it doesn't exist
shiny_data_path.mkdir(parents=True, exist_ok=True)

# Save dataset
cev_all_2021_filter.to_csv(
    shiny_data_path / "cev_2021_cleaned.csv", index=False)

print(f"Dataset saved to: {shiny_data_path / 'cev_2021_cleaned.csv'}")

```


Read in data from American National Election Studies
```{python}
#polarization = pd.read_csv("C:/Users/andre/Documents/GitHub/ppha30538_final_project/data/anes_timeseries_2020_csv_20220210.csv")

polarization = pd.read_csv("/Users/justinesilverstein/Desktop/ppha30538_final_project/anes_timeseries_2020_csv_20220210.csv")
```

Important elements of the ANES Codebook

1. Note on geography:

"Some variables have been removed from the full release dataset in order to protect
 respondent confidentiality....
 Examples of restricted variables include, but are not limited to: detailed geography,
 detailed religious denomination..."

2. Understanding the variables:
" The Codebook includes the following information, where applicable, for each
 variable: the variable name (all variable names start with a “V”, and summary
 variables end with the suffix “x”), variable label (with “PRE:” indicating that it is from
 the pre-election study), question wording/variable meaning, response/code values
 and meanings, universe (where only a subset of respondents appear in a variable,
 which respondents those should be; note that universes are not included for most
 summary variables), associated survey question(s), information about whether
 randomization was used, interviewer instructions, and any other notes about the
 variable"


Subset for the useful columns

List 1: This list contains only pre-election data, it is designed to capture variables
covering some geographic information (V201011, V201013a, V201013b, V201014a, V201014b)

List 2: This list contains only pre-election data, it is designed to capture variables
covering information about self-assessments of political positioning
(i.e. left, right, center)
```{python}
#list 1
subset_list_1 = [column for column in polarization if "V2010" in column]

#list 2
subset_list_2 = [column for column in polarization if "V2012" in column]

#put the lists together
#make a loop 

#empty receiver
subset_list = []

#loop 1
for value in subset_list_1:
        subset_list.append(value)

#loop 2
for value in subset_list_2:
        subset_list.append(value)                    

#subset 
sub_polarization = polarization.filter(items= subset_list)

#add a column that just equals 1 to use for tracking the number
#of entries
sub_polarization["Observations"] = 1
```

Some more data cleaning

Analyzing Question V201200, which is a question asking:

"Where would you place yourself on this scale, or haven’t you
 thought much about this?
 Value Labels-9. Refused -8. Don’t know 
1. Extremely liberal 
2. Liberal 
3. Slightly liberal 
4. Moderate; middle of the road 
5. Slightly conservative 
6. Conservative 
7. Extremely conservative 
99. Haven’t thought much about this"

```{python}
#Make variables more clear

crosswalk_polar = pd.DataFrame({
    "Self_Rating_(V201200)":[-9, -8, 1, 2, 3, 4, 5, 6, 7, 99],
    "Titles_(V201200)": [
        "Refused", "Don't Know", "Extremely Liberal",
        "Liberal", "Slightly Liberal", 
        "Moderate; middle of the road",
        "Slightly conservative",
        "Conservative",
        "Extremely conservative",
        "Haven’t thought much about this"
    ]
    })

#merge using crosswalk
sub_polarization = sub_polarization.merge(crosswalk_polar, left_on = "V201200", right_on = "Self_Rating_(V201200)")

```

Make dataframe where all data is aggregated by state, and then
we can show correlation between measure of polarity and 
the share of respondents in a state who did volunteer work.

Clean data to produce some geographic information

V201013a
```{python}
#Replace FIPS codes with states
from us import states

fips_to_state = {int(state.fips): state.abbr for state in states.STATES}

sub_polarization['US State'] = pd.to_numeric(sub_polarization['V201013a'], errors='coerce')

sub_polarization['US State'] = sub_polarization['US State'].map(fips_to_state)

```


Citation:  American National Election Studies. 2021. ANES 2020 Time Series 
Study Full Release [dataset and documentation]. July 19, 2021 
version. www.electionstudies.org 


2. Plotting (25%)
    * From that data, you will create a minimum of *two* static plots using `altair` or `geopandas`
    * As well as one `shiny` app with one dynamic plot
        * You can also add additional dynamic plots into your app to substitute for a static plot. So, a `shiny` app with 3 dynamic plots will count for full credit.

```{python}
import json

shapefile_path = "/Users/justinesilverstein/Desktop/ppha30538_final_project/cb_2018_us_state_500k.shp"
gdf = gpd.read_file(shapefile_path)


state_counts = cev_all_2021_filter['US State'].value_counts()

# Step 2: Convert the result to a DataFrame for easier viewing (optional)
state_counts_df = state_counts.reset_index()
state_counts_df.columns = ['US State', 'Frequency']

# Step 3: Print the result
print(state_counts_df)
```

# Basic plot to show Frequency of Volunteering Categories
```{python}
filtered_data = cev_all_2021_filter[
    (cev_all_2021_filter['Volunteering_Frequency'] != "Not in Universe") &
    (cev_all_2021_filter['Volunteering_Frequency'].notna()) &
    (cev_all_2021_filter['Volunteering_Frequency'] != "No Answer") &
    (cev_all_2021_filter['Volunteering_Frequency'] != "Refusal") &
    (cev_all_2021_filter['Volunteering_Frequency'] != "Do Not Know")  
]

frequency_counts = filtered_data['Volunteering_Frequency'].value_counts().reset_index()
frequency_counts.columns = ['Volunteering_Frequency', 'Frequency']

chart = alt.Chart(frequency_counts).mark_bar().encode(
    y=alt.Y('Volunteering_Frequency:O', title='Volunteering Frequency'),  
    x=alt.X('Frequency:Q', title='Count'),  
    color=alt.Color('Frequency:Q', scale=alt.Scale(scheme='blues'), title='Frequency'),  
    tooltip=['Volunteering_Frequency', 'Frequency']  
).properties(
    title='Frequency of Volunteering Categories (Excluding "No Answer")',
    width=450,
    height=400
)

chart.show()
```

# Plot to show Volunteering Frequency based on if one voted on the local election
```{python}
#filtered if did volunteer last year
volunteered_last_year = cev_all_2021_filter[
    (cev_all_2021_filter['Volunteering_Frequency'] != "Not in Universe") &  
    (cev_all_2021_filter['Volunteering_Frequency'].notna()) &  
    (cev_all_2021_filter['Volunteering_Frequency'] != "No Answer") &  
    (cev_all_2021_filter['Volunteering_Frequency'] != "Refusal") &  
    (cev_all_2021_filter['Volunteering_Frequency'] != "Do Not Know") &  
    (cev_all_2021_filter['Volunteered_Past_Year'] == "Yes")
]

# Filter data for those who did not volunteer last year
did_not_volunteer_last_year = cev_all_2021_filter[
    (cev_all_2021_filter['Volunteering_Frequency'] != "Not in Universe") &  
    (cev_all_2021_filter['Volunteering_Frequency'].notna()) &  
    (cev_all_2021_filter['Volunteering_Frequency'] != "No Answer") &  
    (cev_all_2021_filter['Volunteering_Frequency'] != "Refusal") &  
    (cev_all_2021_filter['Volunteering_Frequency'] != "Do Not Know") &  
    (cev_all_2021_filter['Volunteered_Past_Year'] == "No")
]

volunteered_counts = volunteered_last_year['Volunteering_Frequency'].value_counts().reset_index()
volunteered_counts.columns = ['Volunteering_Frequency', 'Frequency']
volunteered_counts['Volunteered_Past_Year'] = 'Yes'

did_not_volunteer_counts = did_not_volunteer_last_year['Volunteering_Frequency'].value_counts().reset_index()
did_not_volunteer_counts.columns = ['Volunteering_Frequency', 'Frequency']
did_not_volunteer_counts['Volunteered_Past_Year'] = 'No'

combined_counts = pd.concat([volunteered_counts, did_not_volunteer_counts])

chart = alt.Chart(combined_counts).mark_bar().encode(
    y=alt.Y('Volunteering_Frequency:O', title='Volunteering Frequency'),  
    x=alt.X('Frequency:Q', title='Count'),  
    color=alt.Color('Volunteered_Past_Year:N', title='Volunteered Last Year', legend=alt.Legend(title="Volunteered Last Year")),  
    tooltip=['Volunteering_Frequency', 'Frequency', 'Volunteered_Past_Year']
).properties(
    title='Volunteering Frequency for Those Who Volunteered Last Year vs. Those Who Did Not',
    width=600,
    height=400
)

chart.show()
```

# If they voted or not in the local election but no orange
```{python}
#filtered if did vote
volunteered_last_year = cev_all_2021_filter[
    (cev_all_2021_filter['Volunteering_Frequency'] != "Not in Universe") &  
    (cev_all_2021_filter['Volunteering_Frequency'].notna()) &  
    (cev_all_2021_filter['Volunteering_Frequency'] != "No Answer") &  
    (cev_all_2021_filter['Volunteering_Frequency'] != "Refusal") &  
    (cev_all_2021_filter['Volunteering_Frequency'] != "Do Not Know") &  
    (cev_all_2021_filter['Voted_In_Local_Election'] == "Yes")
]

# Filter data for those who did not vote
did_not_volunteer_last_year = cev_all_2021_filter[
    (cev_all_2021_filter['Volunteering_Frequency'] != "Not in Universe") &  
    (cev_all_2021_filter['Volunteering_Frequency'].notna()) &  
    (cev_all_2021_filter['Volunteering_Frequency'] != "No Answer") &  
    (cev_all_2021_filter['Volunteering_Frequency'] != "Refusal") &  
    (cev_all_2021_filter['Volunteering_Frequency'] != "Do Not Know") &  
    (cev_all_2021_filter['Voted_In_Local_Election'] == "No")
]

volunteered_counts = volunteered_last_year['Volunteering_Frequency'].value_counts().reset_index()
volunteered_counts.columns = ['Volunteering_Frequency', 'Frequency']
volunteered_counts['Voted_In_Local_Election'] = 'Yes'

did_not_volunteer_counts = did_not_volunteer_last_year['Volunteering_Frequency'].value_counts().reset_index()
did_not_volunteer_counts.columns = ['Volunteering_Frequency', 'Frequency']
did_not_volunteer_counts['Voted_In_Local_Election'] = 'No'

combined_counts = pd.concat([volunteered_counts, did_not_volunteer_counts])

chart = alt.Chart(combined_counts).mark_bar().encode(
    y=alt.Y('Volunteering_Frequency:O', title='Volunteering Frequency'),  
    x=alt.X('Frequency:Q', title='Count'),  
    color=alt.Color('Voted_In_Local_Election:N', title='Voted in Local', scale=alt.Scale(domain=['Yes', 'No'], range=['blue', 'red']), legend=alt.Legend(title="Voted")),  
    tooltip=['Volunteering_Frequency', 'Frequency', 'Voted_In_Local_Election']
).properties(
    title='Volunteering Frequency for Those Who Voted vs. Those Who Did Not',
    width=600,
    height=400
)

chart.show()

```

# error graph, delete later
```{python}
filtered_data = cev_all_2021_filter[cev_all_2021_filter['Voted_In_Local_Election'].isin(['Yes', 'No'])]


chart = alt.Chart(filtered_data).mark_boxplot().encode(
    x='Voted_In_Local_Election:N',   
    y='Age:Q',                    
    color='Voted_In_Local_Election:N' 
).properties(
    title='Age Distribution by Voting Status in Local Election'
)

chart.show()
```

# use to show size of volunteering frequency per news consumption?
```{python}
#Frequency_Of_News_Consumption
#Volunteering_Frequency
#Voted_In_Local_Election


import altair as alt
import pandas as pd

# Filter data for those who volunteered and those who did not vote
volunteered_last_year = cev_all_2021_filter[
    (cev_all_2021_filter['Volunteering_Frequency'] != "Not in Universe") &  
    (cev_all_2021_filter['Volunteering_Frequency'].notna()) &  
    (cev_all_2021_filter['Volunteering_Frequency'] != "No Answer") &  
    (cev_all_2021_filter['Volunteering_Frequency'] != "Refusal") &  
    (cev_all_2021_filter['Volunteering_Frequency'] != "Do Not Know") &  
    (cev_all_2021_filter['Voted_In_Local_Election'] == "Yes")
]

did_not_volunteer_last_year = cev_all_2021_filter[
    (cev_all_2021_filter['Volunteering_Frequency'] != "Not in Universe") &  
    (cev_all_2021_filter['Volunteering_Frequency'].notna()) &  
    (cev_all_2021_filter['Volunteering_Frequency'] != "No Answer") &  
    (cev_all_2021_filter['Volunteering_Frequency'] != "Refusal") &  
    (cev_all_2021_filter['Volunteering_Frequency'] != "Do Not Know") &  
    (cev_all_2021_filter['Voted_In_Local_Election'] == "No")
]

# Filter out 'Do Not Know', 'No Answer', and 'Everyday' for Frequency_Of_News_Consumption
filtered_news_consumption_volunteered = volunteered_last_year[
    (cev_all_2021_filter['Frequency_Of_News_Consumption'] != "Do Not Know") &  
    (cev_all_2021_filter['Frequency_Of_News_Consumption'] != "No Answer") &  
    (cev_all_2021_filter['Frequency_Of_News_Consumption'] != "Everyday")
]

filtered_news_consumption_did_not_volunteer = did_not_volunteer_last_year[
    (cev_all_2021_filter['Frequency_Of_News_Consumption'] != "Do Not Know") &  
    (cev_all_2021_filter['Frequency_Of_News_Consumption'] != "No Answer") &  
    (cev_all_2021_filter['Frequency_Of_News_Consumption'] != "Everyday")
]

# Aggregating the counts for volunteered and did not volunteer data
volunteered_counts = filtered_news_consumption_volunteered['Volunteering_Frequency'].value_counts().reset_index()
volunteered_counts.columns = ['Volunteering_Frequency', 'Frequency']
volunteered_counts['Voted_In_Local_Election'] = 'Yes'
volunteered_counts['News_Consumption'] = filtered_news_consumption_volunteered['Frequency_Of_News_Consumption']

did_not_volunteer_counts = filtered_news_consumption_did_not_volunteer['Volunteering_Frequency'].value_counts().reset_index()
did_not_volunteer_counts.columns = ['Volunteering_Frequency', 'Frequency']
did_not_volunteer_counts['Voted_In_Local_Election'] = 'No'
did_not_volunteer_counts['News_Consumption'] = filtered_news_consumption_did_not_volunteer['Frequency_Of_News_Consumption']

# Combining the two datasets for plotting
combined_counts = pd.concat([volunteered_counts, did_not_volunteer_counts])

# Scatter plot
chart = alt.Chart(combined_counts).mark_point(filled=True).encode(
    y=alt.Y('Volunteering_Frequency:O', title='Volunteering Frequency'),  # Categorical variable for Y-axis
    x=alt.X('Frequency:Q', title='Count'),  # Frequency count on X-axis (quantitative)
    color=alt.Color('Voted_In_Local_Election:N', 
                    title='Voted in Local Election',
                    scale=alt.Scale(domain=['Yes', 'No'], range=['blue', 'red']),
                    legend=alt.Legend(title="Voted")),  # Color by whether they voted
    size=alt.Size('News_Consumption:N', title='News Consumption', legend=alt.Legend(title="News Consumption")),  # Size based on News Consumption
    tooltip=['Volunteering_Frequency', 'Frequency', 'Voted_In_Local_Election', 'News_Consumption']  # Tooltip for additional details
).properties(
    title='Volunteering Frequency for Those Who Voted vs. Those Who Did Not with News Consumption',
    width=600,
    height=400
)

chart.show()



```







```{python}
filtered_data = cev_all_2021_filter[
    (cev_all_2021_filter['Frequency_Of_News_Consumption'] != "Not in Universe") &
    (cev_all_2021_filter['Frequency_Of_News_Consumption'].notna())
]

frequency_counts = filtered_data['Frequency_Of_News_Consumption'].value_counts()

print(frequency_counts)
```

```{python}
#with fam
filtered_data = cev_all_2021_filter[
    (cev_all_2021_filter['Discussed_Issues_With_Friends_Family'] != "Not in Universe") &
    (cev_all_2021_filter['Discussed_Issues_With_Friends_Family'].notna())
]

print(filtered_data['Discussed_Issues_With_Friends_Family'].value_counts())
```

```{python}
#with neighbors
filtered_data = cev_all_2021_filter[
    (cev_all_2021_filter['Discussed_Issues_With_Neighbors'] != "Not in Universe") &
    (cev_all_2021_filter['Discussed_Issues_With_Neighbors'].notna())
]

frequency_counts = filtered_data['Discussed_Issues_With_Neighbors'].value_counts()
print(frequency_counts)
```

```{python}
#voted - binary
print(frequency_counts)

filtered_data = cev_all_2021_filter[
    (cev_all_2021_filter['Voted_In_Local_Election'] != "Not in Universe") &
    (cev_all_2021_filter['Voted_In_Local_Election'].notna())
]

frequency_counts = filtered_data['Voted_In_Local_Election'].value_counts()

print(frequency_counts)
```

```{python}
#bumver of hourss
filtered_data = cev_all_2021_filter[
    (cev_all_2021_filter['Hours_Spent_Volunteering'] != "Not in Universe") &
    (cev_all_2021_filter['Hours_Spent_Volunteering'].notna())
]

frequency_counts = filtered_data['Hours_Spent_Volunteering'].value_counts()

print(frequency_counts)
```

```{python}
#Posted_Views_On_Social_Media
filtered_data = cev_all_2021_filter[
    (cev_all_2021_filter['Posted_Views_On_Social_Media'] != "Not in Universe") &
    (cev_all_2021_filter['Posted_Views_On_Social_Media'].notna())
]

frequency_counts = filtered_data['Posted_Views_On_Social_Media'].value_counts()

print(frequency_counts)
```

```{python}
#Community_Improvement_Activities - binary
filtered_data = cev_all_2021_filter[
    (cev_all_2021_filter['Community_Improvement_Activities'] != "Not in Universe") &
    (cev_all_2021_filter['Community_Improvement_Activities'].notna())
]

frequency_counts = filtered_data['Community_Improvement_Activities'].value_counts()

print(frequency_counts)
```

```{python}
#Boycott_Based_On_Values - binary
filtered_data = cev_all_2021_filter[
    (cev_all_2021_filter['Boycott_Based_On_Values'] != "Not in Universe") &
    (cev_all_2021_filter['Boycott_Based_On_Values'].notna())
]

frequency_counts = filtered_data['Boycott_Based_On_Values'].value_counts()

print(frequency_counts)
```

```{python}
#Contacted_Public_Official - can be binary
filtered_data = cev_all_2021_filter[
    (cev_all_2021_filter['Contacted_Public_Official'] != "Not in Universe") &
    (cev_all_2021_filter['Contacted_Public_Official'].notna())
]

frequency_counts = filtered_data['Contacted_Public_Official'].value_counts()

print(frequency_counts)
```






Exploratory graph of polarization
```{python}
import altair as alt
#create list for graph to sort on 
sorting_list = [
        "Refused", "Don't Know", "Extremely Liberal",
        "Liberal", "Slightly Liberal", 
        "Moderate; middle of the road",
        "Slightly conservative",
        "Conservative",
        "Extremely conservative",
        "Haven’t thought much about this"
    ]

alt.Chart(sub_polarization).mark_bar().encode(
    alt.X("Titles_(V201200):N", sort = sorting_list),
    alt.Y("Observations"),
    alt.Color("Titles_(V201200)")
)

```

4. Reproductibility (10%)
    * The project and files should be structured and documented so that the TAs can clone your repository and reproduce your results (see "Final Repository" below) by knitting your `.qmd` and, if needed, downloading the dataset(s) you use using the link provided in the `.qmd` comments
5. Git (10%)
    * You should submit your project as a Git repository.
    * Create multiple branches as you work for different pieces of the analysis. Branches may correspond to work done by different partners or to different features if you are working alone.
    * Your final repository should have one branch: `main`
    * We reserve the right to check the git commit history to ensure that all members have contributed to the project.
6. Extra credit: text processing (up to 10%)
    * Introduce some form of text analysis using natural language processing methods discussed in class.

## Writeup (15%)
* You will then spend *no more than 3 pages* writing up your project. 
* The primary purpose of this writeup is to inform us of what we are reading before we look at your code.
* You should describe your research question, then discuss the approach you took and the coding involved, including discussing any weaknesses or difficulties encountered. 
* Display your static plots, and briefly describe them and your Shiny app. Discuss the policy implications of your findings.
* Finish with a discussion of directions for future work. 
* The top of your writeup should include the names of all group members, their respective sections, and Github user names.

## Presentation (15%)
* On the day of the presentation, one of the group members will be *randomly selected* to give a *8-minute in-class presentation*. All group members must be present.
* Any group member who is not present will receive an automatic 0 for the presentation portion of the final project.
* The presentation will be of slides that largely mirror the structure of the writeup, but will be more focused on discussing the research question and results as opposed to explaining the details of the coding. 

# Final Repository
Your final repository must contain the following:

* Documentation and Meta-data
    * A `requirements.txt` file 
    * A `.gitignore` file that ignores unneeded files (e.g. `venv`) 
* Writeup: a user should be able to knit your `.qmd` file and re-generate the HTML version of your writeup
    * The `.qmd` file associated with your write-up
    * An HTML and PDF'd version of your writeup
    * A folder named `pictures` that contains the files for any pictures required to knit your writeup
* Data
    * A folder named `data` that contains the initial, unmodified dataframes you download and the final versions of the dataframe(s) you built.
    * If the dataset is greater than 100MB, it can hosted on Drive or Dropbox and the link should be provided in your .`qmd` file as a comment
* Shiny app
    * A folder named `shiny-app` that contains the code and any additional files needed to deploy your app
    * A user should be able to deploy your app directly from the command line within this folder


# Key Dates
* By November 1
    * Proposal submitted to Canvas quiz
    * (Optional) meeting with Professor Ganong, Professor Shi, or Head TA Ozzy Houck
    * Sign up for presentation slot
* December 2- December 5: in-class presentations
* December 7, 5PM: final repository submitted via Gradescope
