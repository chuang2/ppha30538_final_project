---
title: "30538 Final Project: Reproducible Research"
author: "Peter Ganong and Maggie Shi" 
date: "today"
format: pdf
execute:
  eval: false
  echo: false
---

# Project Description and Instructions
The goal of this project is to showcase your knowledge of Python by applying it to a research project about a policy topic you are interested in. You will be graded on coding, writeup, and an in-class presentation.

You may work on this project alone, or in groups of up to three students. All groups must be formed declared in the Canvas proposal before any work is done - it is not possible to join one after. 

It is required that you use GitHub, and we may use your past commits to understand your thought process for partial credit. If you working in a group, note that as we are grading we will be looking for multiple commits per individual throughout the project. The division of labor should be approximately evenly across both individuals. While we will lean toward giving the same grade for all group members, it is possible that individuals may receive different grades based on the commit history.

If you choose to form a group, we recommend that you do so with other students in your section. You are allowed to have a group member from another section, but all group members must be available to attend all the group members' lecture sessions. If you are not present when your project is presented, you will not receive credit for the presentation.


# Grading 
## Coding (70%)
The code for the project should have the following components:

1. Data wrangling (25%)
    * You must use a minimum of *two* datasets. 
    * All processing of the data should be handled by your `.qmd` code, including all merging and reshaping. 

```{python}
# General
import pandas as pd
import numpy as np

# Visualization 
import altair as alt

# Geospatial data handling
import geopandas as gpd

# shiny framework
from shiny import App, ui, render


```

```{python}
#Importing the data - AmeriCorps 2021 CEV 
#Source: https://data.americorps.gov/dataset/2021-CEV-Data-Current-Population-Survey-Civic-Enga/rgh8-g2uc/about_data
#Will need to include google drive/dropbox link since > 300MB

cev_2021_raw = pd.read_csv("/Users/charleshuang/Documents/GitHub/student30538/problem_sets/final_project/data/2021_CEV__Current_Population_Survey_Civic_Engagement_and_Volunteering_Supplement_20241031.csv", encoding = 'utf-8')

vcl_supplement_raw = pd.read_csv("/Users/charleshuang/Documents/GitHub/student30538/problem_sets/final_project/data/sep21pub.csv")

```
Most relevant variables to focus on:

Frequency and Type of Volunteering:
PES16: Did the respondent spend any time volunteering for any organization in the past 12 months?
PES16D: Frequency of volunteering (e.g., basically every day, a few times a week).
PTS16E: Approximate hours spent volunteering.
Political Engagement:
PES2: How often the respondent discussed political, societal, or local issues with friends or family.
PES5: How often these discussions occurred with neighbors.
PES13: Contact or visits to a public official to express opinions.
PES14: Boycotting or buying products based on political values or business practices.
Civic Participation and Group Membership:
PES15: Belonging to groups, organizations, or associations in the past 12 months.
Neighbor and Community Interaction:
PES7: Participation in activities to improve their neighborhood or community.
Voting Behavior:
PES11: Whether the respondent voted in the last local elections.
Social Media and News Consumption:
PES9: Posting views about political, societal, or local issues on the internet or social media.
PES10: Frequency of consuming news related to political or societal issues.

Basic Demographics
Age: PRTAGE (Person's age)
Gender: PESEX (Sex of the respondent)
Race/Ethnicity: PTDTRACE (Detailed race and Hispanic origin)
Marital Status: PEMARITL (Marital status of the respondent)
Household Composition: HRNUMHOU (Number of persons in the household)

Potential Confounding Variables
Income: HEFAMINC (Household family income level)
Education: PEEDUCA (Highest level of school completed)
Urban/Rural Status: GTMETSTA (Metropolitan or non-metropolitan status)
Community Involvement: PES7 (Participation in neighborhood or community activities)
Social Media Use: PES9 (Posting views about political, societal, or local issues on the internet or social media)

This code will filter out the 400+ variables in the dataset to only the relevant ones.

First we need to merge the two datasets:

```{python}
vcl_supplement_raw.columns = vcl_supplement_raw.columns.str.lower()

#I found out the data type is int64 for one df and object for the other

cev_2021_raw = cev_2021_raw.astype(str)
vcl_supplement_raw = vcl_supplement_raw.astype(str)

#This finds all the variables in common between the two for a merge
common_keys = list(set(vcl_supplement_raw.columns).intersection(set(cev_2021_raw.columns)))



cev_all_2021 = pd.merge(cev_2021_raw, vcl_supplement_raw, on=common_keys, how="outer")

cev_all_2021.head(5)

#Note: Each row is a person- multiple people in the same household can have same household ID, so should not filter by unique

# We can use a config.py file to keep this readable. Full details are in the config.py file
``` 

```{python}
from config import selected_variables, rename_mapping


# selected_variables = ['hrhhid', 'hrhhid2', etc.]
# This chooses the variables we want from the merged raw data

# rename_mapping = "hrhhid": "Household_ID", "hrhhid2": "Household_ID_2", etc.
# Renaming the variables for clarity


cev_all_2021_filter = cev_all_2021[selected_variables].copy()
#copy avoids potentially modifying original dataframe

cev_all_2021_filter.rename(columns=rename_mapping, inplace=True)

#Debugging: removing duplicate column(s)
cev_all_2021_filter = cev_all_2021_filter.loc[:, ~cev_all_2021_filter.columns.duplicated()]
```


The data is a mix of numeric code and qualitative input, so we need to keep the qualitative input while mapping only numeric codes. The qualitative input is outside of the data dictionary, so it won't get picked up by any mapping functions and will be transmuted into NaN data. We will make a function that identifies all the values in the data that aren't picked up by our data dictionaries in config.py.

For example, here's a sample from config.py:

Renaming pes16 - Volunteered Past Year
In the past 12 months, did [you/[NAME]] spend any time volunteering for any organization or association?

pes16_dict = {
    '1': 'Yes',
    '2': 'No',
    '-1': 'Not in Universe',
    '-3': 'Refusal',
    '-2': 'Do Not Know',
    '-9': 'No Answer',
    '.u': 'No Answer',
    '.r': 'Refusal',
    '.n': 'Not in Universe',
    '.d': 'Do Not Know'
}

If there are some entries in this column that are already coded "Yes" or "No", our existing mapping won't account for them and will turn them into NANs. That's not desirable. We want to catch those and account for them.

```{python}
#For testing purposes, delete later
cev_pre_clean_test = cev_all_2021_filter.copy()


# Attribution: Asked ChatGPT "why isn't config.py updating when I add dictionaries to it; ChatGPT suggested using importlib reload"
# Import and reload config
import importlib
import config
importlib.reload(config)
from config import *

from us import states

# Replace FIPS codes with states

fips_to_state = {int(state.fips): state.abbr for state in states.STATES}

cev_all_2021_filter['US State'] = pd.to_numeric(
    cev_all_2021_filter['US State'], errors='coerce')

cev_all_2021_filter['US State'] = cev_all_2021_filter['US State'].map(
    fips_to_state)

# Replace "Volunteered Past Year" data (pes16)
cev_all_2021_filter['Volunteered_Past_Year'] = cev_all_2021_filter['Volunteered_Past_Year'].map(
    pes16_dict)

# Replace "Volunteering Frequency" (pes16d)
cev_all_2021_filter['Volunteering_Frequency'] = cev_all_2021_filter['Volunteering_Frequency'].map(
    pes16d_dict)

# Replace "Hours Spent Volunteering" (pts16e)
cev_all_2021_filter['Hours_Spent_Volunteering'] = cev_all_2021_filter['Hours_Spent_Volunteering'].map(
    pts16e_dict)

# Replace "Discussed Issues with Friends/Family" data (pes2)
cev_all_2021_filter['Discussed_Issues_With_Friends_Family'] = cev_all_2021_filter['Discussed_Issues_With_Friends_Family'].map(
    pes2_dict)

# Replace "Discussed Issues with Neighbors" data (pes5)
cev_all_2021_filter['Discussed_Issues_With_Neighbors'] = cev_all_2021_filter['Discussed_Issues_With_Neighbors'].map(
    pes5_dict)

# Replace "Contacted Public Official" data (pes13)
cev_all_2021_filter['Contacted_Public_Official'] = cev_all_2021_filter['Contacted_Public_Official'].map(
    pes13_dict)

# Replace "Boycott Based on Values" data (pes14)
cev_all_2021_filter['Boycott_Based_On_Values'] = cev_all_2021_filter['Boycott_Based_On_Values'].map(
    pes14_dict)

# Replace "Belonged to Groups" data (pes15)
cev_all_2021_filter['Belonged_To_Groups'] = cev_all_2021_filter['Belonged_To_Groups'].map(
    pes15_dict)


# Replace "Community Improvement Activities" data (pes7)
cev_all_2021_filter['Community_Improvement_Activities'] = cev_all_2021_filter['Community_Improvement_Activities'].map(
    pes7_dict)

# Replace "Voted in Local Election" data (pes11)
cev_all_2021_filter['Voted_In_Local_Election'] = cev_all_2021_filter['Voted_In_Local_Election'].map(
    pes11_dict)

# Replace "Posted Views on Social Media" data (pes9)
cev_all_2021_filter['Posted_Views_On_Social_Media'] = cev_all_2021_filter['Posted_Views_On_Social_Media'].map(
    pes9_dict)

# Replace "Frequency of News Consumption" data (pes10)
cev_all_2021_filter['Frequency_Of_News_Consumption'] = cev_all_2021_filter['Frequency_Of_News_Consumption'].map(
    pes10_dict)

# Replace "Age" data (prtage)
cev_all_2021_filter['Age'] = cev_all_2021_filter['Age'].map(prtage_dict)

# Replace "Gender" data (pesex)
cev_all_2021_filter['Gender'] = cev_all_2021_filter['Gender'].map(pesex_dict)

# Replace "Race/Ethnicity" data (ptdtrace)
cev_all_2021_filter['Race_Ethnicity'] = cev_all_2021_filter['Race_Ethnicity'].map(
    ptdtrace_dict)

# Replace "Marital Status" data (pemaritl)
cev_all_2021_filter['Marital_Status'] = cev_all_2021_filter['Marital_Status'].map(
    pemaritl_dict)

# Replace "Household Size" data (hrnumhou)
cev_all_2021_filter['Household_Size'] = cev_all_2021_filter['Household_Size'].map(
    hrnumhou_dict)

# Replace "Family Income Level" data (hefaminc)
cev_all_2021_filter['Family_Income_Level'] = cev_all_2021_filter['Family_Income_Level'].map(
    hefaminc_dict)

# Replace "Education Level" data (peeduca_dict)
cev_all_2021_filter['Education_Level'] = cev_all_2021_filter['Education_Level'].map(
    peeduca_dict)

# Replace "Urban Rural Status" data (gtmetsta_dict)
cev_all_2021_filter['Urban_Rural_Status'] = cev_all_2021_filter['Urban_Rural_Status'].map(
    gtmetsta_dict)

```

Lastly, export the cleaned data as a csv for plotting purposes

```{python}
import os
from pathlib import Path

shiny_data_path = Path("shiny-app/basic-app/data")

# Create directory if it doesn't exist
shiny_data_path.mkdir(parents=True, exist_ok=True)

# Save dataset
cev_all_2021_filter.to_csv(
    shiny_data_path / "cev_2021_cleaned.csv", index=False)

print(f"Dataset saved to: {shiny_data_path / 'cev_2021_cleaned.csv'}")

```

2. Plotting (25%)
    * From that data, you will create a minimum of *two* static plots using `altair` or `geopandas`
    * As well as one `shiny` app with one dynamic plot
        * You can also add additional dynamic plots into your app to substitute for a static plot. So, a `shiny` app with 3 dynamic plots will count for full credit.

```{python}

```


4. Reproductibility (10%)
    * The project and files should be structured and documented so that the TAs can clone your repository and reproduce your results (see "Final Repository" below) by knitting your `.qmd` and, if needed, downloading the dataset(s) you use using the link provided in the `.qmd` comments
5. Git (10%)
    * You should submit your project as a Git repository.
    * Create multiple branches as you work for different pieces of the analysis. Branches may correspond to work done by different partners or to different features if you are working alone.
    * Your final repository should have one branch: `main`
    * We reserve the right to check the git commit history to ensure that all members have contributed to the project.
6. Extra credit: text processing (up to 10%)
    * Introduce some form of text analysis using natural language processing methods discussed in class.

## Writeup (15%)
* You will then spend *no more than 3 pages* writing up your project. 
* The primary purpose of this writeup is to inform us of what we are reading before we look at your code.
* You should describe your research question, then discuss the approach you took and the coding involved, including discussing any weaknesses or difficulties encountered. 
* Display your static plots, and briefly describe them and your Shiny app. Discuss the policy implications of your findings.
* Finish with a discussion of directions for future work. 
* The top of your writeup should include the names of all group members, their respective sections, and Github user names.

## Presentation (15%)
* On the day of the presentation, one of the group members will be *randomly selected* to give a *8-minute in-class presentation*. All group members must be present.
* Any group member who is not present will receive an automatic 0 for the presentation portion of the final project.
* The presentation will be of slides that largely mirror the structure of the writeup, but will be more focused on discussing the research question and results as opposed to explaining the details of the coding. 

# Final Repository
Your final repository must contain the following:

* Documentation and Meta-data
    * A `requirements.txt` file 
    * A `.gitignore` file that ignores unneeded files (e.g. `venv`) 
* Writeup: a user should be able to knit your `.qmd` file and re-generate the HTML version of your writeup
    * The `.qmd` file associated with your write-up
    * An HTML and PDF'd version of your writeup
    * A folder named `pictures` that contains the files for any pictures required to knit your writeup
* Data
    * A folder named `data` that contains the initial, unmodified dataframes you download and the final versions of the dataframe(s) you built.
    * If the dataset is greater than 100MB, it can hosted on Drive or Dropbox and the link should be provided in your .`qmd` file as a comment
* Shiny app
    * A folder named `shiny-app` that contains the code and any additional files needed to deploy your app
    * A user should be able to deploy your app directly from the command line within this folder


# Key Dates
* By November 1
    * Proposal submitted to Canvas quiz
    * (Optional) meeting with Professor Ganong, Professor Shi, or Head TA Ozzy Houck
    * Sign up for presentation slot
* December 2- December 5: in-class presentations
* December 7, 5PM: final repository submitted via Gradescope
