{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"30538 Final Project: Reproducible Research - Volunteerism, Engagement, and Polarization in the U.S.\"\n",
        "author: \"Andrew White, Charles Huang, Justine Silverstein\" \n",
        "date: \"December 7, 2024\"\n",
        "format: pdf\n",
        "execute:\n",
        "  echo: false\n",
        "  warning: false\n",
        "---"
      ],
      "id": "39e6c822"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# General\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualization\n",
        "import altair as alt\n",
        "\n",
        "# shiny framework\n",
        "from shiny import App, ui, render\n",
        "\n",
        "# for spatial data\n",
        "from us import states  # Background"
      ],
      "id": "bd206301",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Background\n",
        "\n",
        "This project began as a shared interest in trends behind volunteering rates in America, as two of our members (Justine and Charles) are AmeriCorps alumni.\n",
        "\n",
        "For the past few years, concerns about the American public's increasing rates of isolation, decreasing lack of civic engagement and faith in institutions, and greater rates of political polarization have been prominent in the news and media. Our personal experiences with AmeriCorps and volunteering have taught us that volunteering can be effective at reducing isolation, increasing civic engagement/community awareness, and decreasing negative polarization towards \"the other side\". However, is volunteering a legitimate part of a public policy solution to these issues, or is it just a red herring?\n",
        "\n",
        "Our research questions were: \n",
        "1. What is the current state of volunteerism, political engagement and polarization in America? \n",
        "2. What factors make people more likely to volunteer or be civically engaged?\n",
        "\n",
        "\n",
        "# 2. Data Importing/Cleaning\n",
        "\n",
        "Our datasets for this project were:\n",
        "\n",
        "1. AmeriCorps CEV (Civic Engagement and Volunteering Supplement) for 2021\n",
        "2. U.S. Census Bureau Volunteering and Civic Life (VCL) Supplement - September 2021\n",
        "3. ANES (American National Election Studies) Time Series Data, 2020\n",
        "\n",
        "#1 and #2 primarily contain respondent information about volunteering and measures of civic engagement, while #3 contains information on political affiliation and polarization.\n",
        "\n",
        "We are importing the data from the AmeriCorps and ANES websites. Because the datasets are over 100 MB, we include a Google Drive link here:\n",
        "\n",
        "https://drive.google.com/drive/folders/1PUTN2pyh78MLoK0RVtGnf1ZwiM1BAAuV?usp=sharing\n"
      ],
      "id": "093d9727"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Google Drive link for data: https://drive.google.com/drive/folders/1PUTN2pyh78MLoK0RVtGnf1ZwiM1BAAuV?usp=sharing\n",
        "\n",
        "\n",
        "cev_2021_raw = pd.read_csv(\"/Users/charleshuang/Documents/GitHub/student30538/problem_sets/final_project/data/2021_CEV__Current_Population_Survey_Civic_Engagement_and_Volunteering_Supplement_20241031.csv\", encoding = 'utf-8')\n",
        "\n",
        "vcl_supplement_raw = pd.read_csv(\"/Users/charleshuang/Documents/GitHub/student30538/problem_sets/final_project/data/sep21pub.csv\")\n",
        "\n",
        "polarization = pd.read_csv(\"/Users/charleshuang/Documents/GitHub/student30538/problem_sets/final_project/data/anes_timeseries_2020_csv_20220210.csv\")"
      ],
      "id": "f90128c7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As there are over 400 variables in the CEV and VCL data, we focused on the 20 most relevant variables in the following categories:\n",
        "\n",
        "1. Frequency and Type of Volunteering\n",
        "2. Political Engagement (did respondents discuss politics, did they write to elected officials, boycott products, etc.)\n",
        "3. Civic/Community Participation (did respondents belong to groups/associations, interact with neighbors, etc.)\n",
        "4. Basic demographics (age, gender, race, income, education, etc.)\n",
        "\n",
        "Because the CEV and VCL data use similar variable names (by design), we were able to merge the two datasets together after cleaning the column names. Since the data values in the CEV/VCL data are entered in numeric codes (-1, 1, 2, etc.), we also created mapping functions with dictionaries to convert the data as needed.\n",
        "\n",
        "(One notable issue we encountered with cleaning the CEV/VCL data was a hetereogeneous mix of numeric code and qualitative input. We made an additional helper function that identifies all the values in the data that aren't picked up by our data dictionaries- this function is located in our config.py file.)\n",
        "\n",
        "# 2b. Data cleaning - ANES data\n",
        "\n",
        "As with the CEV/VCL data, our goal was to subset the data so that it only contains relevant variables. We accomplished this by making two lists- one designed to capture variables covering geographic information (V201011, V201013a, V201013b, V201014a, V201014b), and one designed to capture variables covering information about assessments of political positioning (i.e. left, right, center)\n",
        "\n",
        "Similarly, we also used a mapping function to change numerical codes to qualitative data in two relevant questions: \n",
        "\n",
        "V201200 - \"Where would you place yourself on this [extremely liberal to extremely conservative] scale, or haven’t you thought much about this?\"\n",
        "\n",
        "V201228 - \"Generally speaking, do you usually think of yourself as [a Democrat, a Republican / a Republican, a Democrat], an independent, or something else?\"\n",
        "\n",
        "# 3. Custom Variables\n",
        "\n",
        "We devised two custom measures of political engagement and polarization derived from the survey results:\n",
        "\n",
        "I. Political Engagement Score \n",
        "\n",
        "We chose five of the most relevant questions from the CEV/VCL data and weighted each based on their level of effort:\n",
        "\n",
        "1. “How frequently do you talk to a family member/neighbor about politics?” (15%)\n",
        "2. “How frequently do you post political views on social media?” (15%)\n",
        "3. “How frequently do you consume political news/media?” (10%)\n",
        "4. “Did you contact an elected official to express your opinion in the last 12 months?” (30%) \n",
        "5. “Did you boycott a company based on their values in the last 12 months?” (30%)\n",
        "\n",
        "This generated a score from 0 - 100 that we could use as a (imperfect) proxy for political engagement. We mutated a new variable to measure this and added it to our dataset.\n",
        "\n",
        "II. Polarization Score\n",
        "\n",
        "In a paper on quantifying polarization written by Aaron Bramson et al (https://inferenceproject.yale.edu/sites/default/files/688938.pdf), the authors examine a range of polarization indicators. A relatively simple (and in some ways problematic) measurement is called spread, or dispersion. Bramson et al. explain: \"Polarization...can be measured as the value of the agent with the highest belief value minus the value of the agent with the lowest belief value.\"\n",
        "\n",
        "We (imperfectly) approximate this using two more variables: V201206 and V201207. These ask respondents to position political parties on the political spectrum. We selected the most ideologically distant nodes on the personal ideology scale (extremely liberal and extremely conservative) and capture how far apart their conceptions of each party are, on average.\n",
        "\n",
        "We created a scale to assign the different ideological positions on a spectrum, namely:\n",
        "-3, -2, and -1 are \"Extremely Liberal\", \"Liberal\",  and \"Slightly Liberal\"; \n",
        "0 is \"Moderate; middle of the road\"; \n",
        "1, 2, and 3 are \"Slightly conservative\", \"Conservative\", and \"Extremely conservative.\"\n",
        "\n",
        "For example, if the average extremely liberal respondent in Texas places Democrats at -1 (slightly liberal) and the average for the extremely conservative respondents is 3 (extremely conservative), then the distance between the two is 4, meaning Texas would have a spread of 4 for this question.\n",
        "\n",
        "\n",
        "# 4. Static Plots and Outcomes\n",
        "\n",
        "# Caveats\n",
        "\n",
        "Before discussing the data, we acknowledge we cannot discuss patterns over time as we only have data from 2021 in the case of the AmeriCorps and U.S. Census data, and 2020 in the case of the ANES data. However, the data is still useful as we can garner a lot from even a snapshot in time, especially as this was right after the height of the COVID pandemic and a highly contentious election. Furthermore (as noted in the shiny app), many entries were missing from the datasets due to nonresponse. As an example, over 80% respondents did not answer a majority of our political engagement questions, forcing us to exclude them from the analysis. While we believe our analyses still provide useful information, this potential selection bias should be taken into account.\n",
        "\n",
        "# 4a. Exploratory Analysis - Volunteering\n",
        "\n",
        "When initially working with the data, we generated multiple plots with different variables to see if we could notice any noteworthy trends between volunteering frequency and civic indicators such as public officials, boycotts, etc. (These charts are not shown here for space, but the output is included in our code.)\n",
        "\n",
        "As part of our exploratory analysis, we also ran a groupby on state-level data to see if there was any correlation between the number of volunteers per state and the average hours volunteered; however, there did not seem to be any correlation between the two.\n",
        "\n",
        "We want to highlight two charts out of the ones we produced. The first chart depicts the top and bottom five states by average hours spent volunteering:\n",
        "\n",
        "![Top 5 and Bottom 5 US States by average hours spent volunteering]('top_bottom_5_states_avg_volunteering.png')\n",
        "\n",
        "The second chart depicts volunteering frequency when measured against voters and nonvoters:\n",
        "\n",
        "![Volunteering Frequency for Voters and Non-Voters]('if_volunteered_last_year.png')\n",
        "\n",
        "An interesting point from our exploratory analysis is that in each volunteering category, the majority of people did vote in their local election. However, it is unclear if this is simply correlation, as AmeriCorps may disproportionately attract the kind of person already primed to vote in their local election and be politically engaged. We will engage this question of correlation further with our Shiny app results. \n",
        "\n",
        "\n",
        "# 4b. Polarization Analysis\n",
        "\n",
        "With the ANES data, we focused more specifically on measuring political polarization, to try to examine our hypothesis that volunteering would correlate negatively with polarization. \n",
        "\n",
        "As mentioned above, we devised a simple \"spread\" variable from Bramson et al. to measure polarization. We then graphed each state’s spread alongside average political engagement score and average volunteer hours. As an example, here is a graph of spread of views on Democrat Party ideological position, including volunteering hours: \n",
        "\n",
        "![Spread of views on Democrat Party](dem_graph_spread_2.png)\n",
        "\n",
        "We found that these graphs do not appear to show a significant meaningful correlation between extreme views and volunteering in either Democrat or Republican analyses; we may have chosen some of the states with very high or very low spread, and it is clear that there is not much of a relationship, with high spread being found in some higher-volunteer states and some lower-volunteer states. \n",
        "\n",
        "In the future, causal techniques such as regression analysis with controls for potential bias coming from variables such as income and education, or a difference-in-differences approach examining specific states over time, could better help to precisely measure polarization alongside political engagement.\n",
        "\n",
        "\n",
        "# 5. Dynamic Plots in Shiny - Demographics vs. Volunteering Rate/Political Engagement\n",
        "\n",
        "Building off of our exploratory analysis, we wanted to more easily see the correlations between volunteerism, political engagement, and potential confounders like income and education. We made a Shiny dashboard app using the CEV/VCL data that lets us see demographics (age, education level, income, US state, etc.) on the X-axis and the user's choice of volunteer rates or political engagement on the Y-axis. \n",
        "\n",
        "A screenshot of the app is here:\n",
        "![Shiny dashboard screenshot](shiny_screenshot.png)\n",
        "\n",
        "As an example, we can see here that volunteering is positively correlated with educational attainment, with over 25% of PhD/professional/master’s degree holders having volunteered in 2021.\n",
        "\n",
        "Using this app, we were able to find the most common traits associated with volunteering and civic engagement for 2021: family income and education, marital status, age, and being of White or Native American/Alaskan Indian heritage.\n",
        "\n",
        "We also found that women and rural inhabitants were slightly more likely to volunteer than men/urban inhabitants, but civic engagement remained the same. Additionally (but not surprisingly) social media was a negative predictor of volunteering, but not civic engagement. \n",
        "\n",
        "This analysis reveals something critical about our hypothesis- while volunteering can still be a solution to low civic engagement, we can’t dismiss that both are simply correlated with other overarching demographic factors like income, education, and race, which makes sense as those factors can indicate well-off people having more resources and time to volunteer than others.\n",
        "\n",
        "\n",
        "# 6. Conclusion/Takeaways\n",
        "\n",
        "As mentioned before, our data and analysis has several disclaimers and caveats that we cannot fully account for. Nevertheless, our takeaways are here in order:\n",
        "\n",
        "1. Volunteers are more likely to vote than non-volunteers, but this is less likely to be a causation and more a correlation of demographic factors\n",
        "2. We did not find a meaningful correlation between volunteering and polarized attitudes; the evidence that volunteering in particular has a positive effect on polarization and engagement seems weak. \n",
        "3. We found that predictors of volunteering and civic engagement are concentrated in disproportionately well-off, privileged populations.\n",
        "\n",
        "For organizations like AmeriCorps that want to attract younger or more diverse volunteers, as well as improving civic participation/engagement in general, this has important implications- organizations like those should consider that simple appeals to volunteer more, or attempts to diversify volunteer populations, may not mean much without additional incentives that can address the structural barriers of volunteering.\n",
        "\n",
        "While volunteering can still be a solution to low civic engagement, and we can speak personally to its interpersonal benefits, we can’t dismiss that both are simply correlated with other overarching demographic factors like income, education, and race. This should give us pause to the theory that volunteering is a neat solution to reducing polarization and improving civic engagement in and of itself, but future studies can examine specific populations of low-income or other \"non-typical\" volunteers that reported positive outcomes- perhaps volunteering itself has certain aspects (like community, sense of purpose, etc.) that can still be valuable regardless of socioeconomic status.\n",
        "\n",
        "# 7. Coding Analysis (Not Shown in Writeup)\n"
      ],
      "id": "4113fb40"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "vcl_supplement_raw.columns = vcl_supplement_raw.columns.str.lower()\n",
        "\n",
        "cev_2021_raw = cev_2021_raw.astype(str)\n",
        "vcl_supplement_raw = vcl_supplement_raw.astype(str)\n",
        "\n",
        "#This finds all the variables in common between the two for a merge\n",
        "common_keys = list(set(vcl_supplement_raw.columns).intersection(set(cev_2021_raw.columns)))\n",
        "\n",
        "cev_all_2021 = pd.merge(cev_2021_raw, vcl_supplement_raw, on=common_keys, how=\"outer\")\n",
        "\n",
        "cev_all_2021.head(5)\n",
        "\n",
        "#Note: Each row is a person- multiple people in the same household can have same household ID, so should not filter by unique\n",
        "\n",
        "# We can use a config.py file to keep this readable. Full details are in the config.py file"
      ],
      "id": "99337a7e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from config import selected_variables, rename_mapping\n",
        "\n",
        "# selected_variables = ['hrhhid', 'hrhhid2', etc.]\n",
        "# This chooses the variables we want from the merged raw data\n",
        "\n",
        "# rename_mapping = \"hrhhid\": \"Household_ID\", \"hrhhid2\": \"Household_ID_2\", etc.\n",
        "# Renaming the variables for clarity\n",
        "\n",
        "\n",
        "cev_all_2021_filter = cev_all_2021[selected_variables].copy()\n",
        "#copy avoids potentially modifying original dataframe\n",
        "\n",
        "cev_all_2021_filter.rename(columns=rename_mapping, inplace=True)\n",
        "\n",
        "#Debugging: removing duplicate column(s)\n",
        "cev_all_2021_filter = cev_all_2021_filter.loc[:, ~cev_all_2021_filter.columns.duplicated()]"
      ],
      "id": "2f30afd2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Attribution: Asked ChatGPT \"why isn't config.py updating when I add dictionaries to it; ChatGPT suggested using importlib reload\"\n",
        "# Import and reload config\n",
        "import importlib\n",
        "import config\n",
        "importlib.reload(config)\n",
        "from config import *\n",
        "import us as states\n",
        "\n",
        "# Replace FIPS codes with states\n",
        "\n",
        "fips_to_state = {int(state.fips): state.abbr for state in states.STATES}\n",
        "\n",
        "cev_all_2021_filter['US State'] = pd.to_numeric(\n",
        "    cev_all_2021_filter['US State'], errors='coerce')\n",
        "\n",
        "cev_all_2021_filter['US State'] = cev_all_2021_filter['US State'].map(\n",
        "    fips_to_state)\n",
        "\n",
        "# Replace \"Volunteered Past Year\" data (pes16)\n",
        "cev_all_2021_filter['Volunteered_Past_Year'] = cev_all_2021_filter['Volunteered_Past_Year'].map(\n",
        "    pes16_dict)\n",
        "\n",
        "# Replace \"Volunteering Frequency\" (pes16d)\n",
        "cev_all_2021_filter['Volunteering_Frequency'] = cev_all_2021_filter['Volunteering_Frequency'].map(\n",
        "    pes16d_dict)\n",
        "\n",
        "# Replace \"Hours Spent Volunteering\" (pts16e)\n",
        "cev_all_2021_filter['Hours_Spent_Volunteering'] = cev_all_2021_filter['Hours_Spent_Volunteering'].map(\n",
        "    pts16e_dict)\n",
        "\n",
        "# Replace \"Discussed Issues with Friends/Family\" data (pes2)\n",
        "cev_all_2021_filter['Discussed_Issues_With_Friends_Family'] = cev_all_2021_filter['Discussed_Issues_With_Friends_Family'].map(\n",
        "    pes2_dict)\n",
        "\n",
        "# Replace \"Discussed Issues with Neighbors\" data (pes5)\n",
        "cev_all_2021_filter['Discussed_Issues_With_Neighbors'] = cev_all_2021_filter['Discussed_Issues_With_Neighbors'].map(\n",
        "    pes5_dict)\n",
        "\n",
        "# Replace \"Contacted Public Official\" data (pes13)\n",
        "cev_all_2021_filter['Contacted_Public_Official'] = cev_all_2021_filter['Contacted_Public_Official'].map(\n",
        "    pes13_dict)\n",
        "\n",
        "# Replace \"Boycott Based on Values\" data (pes14)\n",
        "cev_all_2021_filter['Boycott_Based_On_Values'] = cev_all_2021_filter['Boycott_Based_On_Values'].map(\n",
        "    pes14_dict)\n",
        "\n",
        "# Replace \"Belonged to Groups\" data (pes15)\n",
        "cev_all_2021_filter['Belonged_To_Groups'] = cev_all_2021_filter['Belonged_To_Groups'].map(\n",
        "    pes15_dict)\n",
        "\n",
        "\n",
        "# Replace \"Community Improvement Activities\" data (pes7)\n",
        "cev_all_2021_filter['Community_Improvement_Activities'] = cev_all_2021_filter['Community_Improvement_Activities'].map(\n",
        "    pes7_dict)\n",
        "\n",
        "# Replace \"Voted in Local Election\" data (pes11)\n",
        "cev_all_2021_filter['Voted_In_Local_Election'] = cev_all_2021_filter['Voted_In_Local_Election'].map(\n",
        "    pes11_dict)\n",
        "\n",
        "# Replace \"Posted Views on Social Media\" data (pes9)\n",
        "cev_all_2021_filter['Posted_Views_On_Social_Media'] = cev_all_2021_filter['Posted_Views_On_Social_Media'].map(\n",
        "    pes9_dict)\n",
        "\n",
        "# Replace \"Frequency of News Consumption\" data (pes10)\n",
        "cev_all_2021_filter['Frequency_Of_News_Consumption'] = cev_all_2021_filter['Frequency_Of_News_Consumption'].map(\n",
        "    pes10_dict)\n",
        "\n",
        "# Replace \"Age\" data (prtage)\n",
        "cev_all_2021_filter['Age'] = cev_all_2021_filter['Age'].map(prtage_dict)\n",
        "\n",
        "# Replace \"Gender\" data (pesex)\n",
        "cev_all_2021_filter['Gender'] = cev_all_2021_filter['Gender'].map(pesex_dict)\n",
        "\n",
        "# Replace \"Race/Ethnicity\" data (ptdtrace)\n",
        "cev_all_2021_filter['Race_Ethnicity'] = cev_all_2021_filter['Race_Ethnicity'].map(\n",
        "    ptdtrace_dict)\n",
        "\n",
        "# Replace \"Marital Status\" data (pemaritl)\n",
        "cev_all_2021_filter['Marital_Status'] = cev_all_2021_filter['Marital_Status'].map(\n",
        "    pemaritl_dict)\n",
        "\n",
        "# Replace \"Household Size\" data (hrnumhou)\n",
        "cev_all_2021_filter['Household_Size'] = cev_all_2021_filter['Household_Size'].map(\n",
        "    hrnumhou_dict)\n",
        "\n",
        "# Replace \"Family Income Level\" data (hefaminc)\n",
        "cev_all_2021_filter['Family_Income_Level'] = cev_all_2021_filter['Family_Income_Level'].map(\n",
        "    hefaminc_dict)\n",
        "\n",
        "# Replace \"Education Level\" data (peeduca_dict)\n",
        "cev_all_2021_filter['Education_Level'] = cev_all_2021_filter['Education_Level'].map(\n",
        "    peeduca_dict)\n",
        "\n",
        "# Replace \"Urban Rural Status\" data (gtmetsta_dict)\n",
        "cev_all_2021_filter['Urban_Rural_Status'] = cev_all_2021_filter['Urban_Rural_Status'].map(\n",
        "    gtmetsta_dict)"
      ],
      "id": "d588ffb6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#list 1\n",
        "subset_list_1 = [column for column in polarization if \"V2010\" in column]\n",
        "\n",
        "#list 2\n",
        "subset_list_2 = [column for column in polarization if \"V2012\" in column]\n",
        "\n",
        "#put the lists together\n",
        "#make a loop \n",
        "\n",
        "#empty receiver\n",
        "subset_list = []\n",
        "\n",
        "#loop 1\n",
        "for value in subset_list_1:\n",
        "        subset_list.append(value)\n",
        "\n",
        "#loop 2\n",
        "for value in subset_list_2:\n",
        "        subset_list.append(value)                    \n",
        "\n",
        "#subset \n",
        "sub_polarization = polarization.filter(items= subset_list)\n",
        "\n",
        "#add a column that just equals 1 to use for tracking the number\n",
        "#of entries\n",
        "sub_polarization[\"Observations\"] = 1"
      ],
      "id": "e9a7d138",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "##Note: The below debugging code was suggested by ChatGPT to deal with some column value errors caused by political_engagement_score mutation. We weren't sure how to fix the errors without taking out the debugging code.\n",
        "\n",
        "# Debugging code - Before engagement score calculation\n",
        "print(\"Columns before adding engagement score:\")\n",
        "print(cev_all_2021_filter.columns.tolist())\n",
        "print(\"\\nShape before:\", cev_all_2021_filter.shape)\n",
        "\n",
        "\n",
        "# Mutate the engagement score variable we came up with in config.py\n",
        "cev_all_2021_filter = add_engagement_score(cev_all_2021_filter)\n",
        "\n",
        "# More debugging code\n",
        "print(\"\\nColumns after adding engagement score:\")\n",
        "print(cev_all_2021_filter.columns.tolist())\n",
        "print(\"\\nShape after:\", cev_all_2021_filter.shape)\n",
        "\n",
        "# Before saving\n",
        "print(\"\\nVerifying engagement score columns exist:\")\n",
        "print(\"'political_engagement_score' exists:\",\n",
        "      'political_engagement_score' in cev_all_2021_filter.columns)\n",
        "print(\"'engagement_level' exists:\",\n",
        "      'engagement_level' in cev_all_2021_filter.columns)"
      ],
      "id": "73e55be0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# confirm this code exports the data into the 'data' folder into the repo\n",
        "from pathlib import Path\n",
        "\n",
        "# Lastly, export the cleaned data as a csv for plotting purposes\n",
        "shiny_data_path = Path(\"shiny-app/basic-app/data\")\n",
        "\n",
        "# Create directory if it doesn't exist\n",
        "shiny_data_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Save dataset\n",
        "cev_all_2021_filter.to_csv(\n",
        "    shiny_data_path / \"cev_2021_cleaned.csv\", index=False)\n",
        "\n",
        "print(f\"Dataset saved to: {shiny_data_path / 'cev_2021_cleaned.csv'}\")"
      ],
      "id": "34de1200",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "'''As with the CEV/VCL data, our goal was to subset the data so that it only contains relevant variables. We accomplish this by making two lists:\n",
        "\n",
        "List 1: This list is designed to capture variables covering geographic information (V201011, V201013a, V201013b, V201014a, V201014b)\n",
        "\n",
        "List 2: This list is designed to capture variables covering information about assessments of political positioning (i.e. left, right, center)\n",
        "\n",
        "'''\n",
        "\n",
        "#list 1\n",
        "subset_list_1 = [column for column in polarization if \"V2010\" in column]\n",
        "\n",
        "#list 2\n",
        "subset_list_2 = [column for column in polarization if \"V2012\" in column]\n",
        "\n",
        "#put the lists together\n",
        "#make a loop \n",
        "\n",
        "#empty receiver\n",
        "subset_list = []\n",
        "\n",
        "#loop 1\n",
        "for value in subset_list_1:\n",
        "        subset_list.append(value)\n",
        "\n",
        "#loop 2\n",
        "for value in subset_list_2:\n",
        "        subset_list.append(value)                    \n",
        "\n",
        "#subset \n",
        "sub_polarization = polarization.filter(items= subset_list)\n",
        "\n",
        "#add a column that just equals 1 to use for tracking the number\n",
        "#of entries\n",
        "sub_polarization[\"Observations\"] = 1"
      ],
      "id": "505e44db",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Make variables more clear\n",
        "\n",
        "'''Analyzing Question V201200, which is a question asking:\n",
        "\n",
        "\"Where would you place yourself on this scale, or haven’t you\n",
        " thought much about this?\n",
        " Value Labels-9. Refused -8. Don’t know \n",
        "1. Extremely Liberal \n",
        "2. Liberal \n",
        "3. Slightly Liberal \n",
        "4. Moderate; middle of the road \n",
        "5. Slightly Conservative \n",
        "6. Conservative \n",
        "7. Extremely Conservative \n",
        "99. Haven’t thought much about this\"\n",
        "'''\n",
        "\n",
        "crosswalk_polar = pd.DataFrame({\n",
        "    \"Self_Rating_(V201200)\":[-9, -8, 1, 2, 3, 4, 5, 6, 7, 99],\n",
        "    \"Ideology_(V201200)\": [\n",
        "        \"Refused\", \"Don't Know\", \"Extremely Liberal\",\n",
        "        \"Liberal\", \"Slightly Liberal\", \n",
        "        \"Moderate; middle of the road\",\n",
        "        \"Slightly Conservative\",\n",
        "        \"Conservative\",\n",
        "        \"Extremely Conservative\",\n",
        "        \"Haven’t thought much about this\"\n",
        "    ]\n",
        "    })\n",
        "\n",
        "#merge using crosswalk\n",
        "sub_polarization = sub_polarization.merge(crosswalk_polar, left_on = \"V201200\", right_on = \"Self_Rating_(V201200)\")\n",
        "\n",
        "#We use this data to make a dataframe aggregated by state, and then we can show correlation between measure of polarity and the share of respondents in a state who did volunteer work."
      ],
      "id": "acc04c41",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Replace FIPS codes with states\n",
        "\n",
        "# Note that we previously used two ANES variables as US State variables,  with only \"US State 2\" being used in analysis, purely because it has more in-universe entries. This appears to be partially due to respondent reactions to different questions, and partially due to information restrictions on the dataset. As such, \"US State\" is only used for CEV data. \n",
        "\n",
        "from us import states\n",
        "\n",
        "fips_to_state = {int(state.fips): state.abbr for state in states.STATES}\n",
        "\n",
        "sub_polarization[\"US State 2\"] = pd.to_numeric(sub_polarization['V201014b'], errors='coerce')\n",
        "\n",
        "sub_polarization['US State 2'] = sub_polarization['US State 2'].map(fips_to_state)\n"
      ],
      "id": "f1127b2f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "'''\n",
        "We clean data related to V201228, which asks:\n",
        "\n",
        "\"Generally speaking, do you usually think of yourself as [a Democrat, a Republican / a Republican, a Democrat], an\n",
        "independent, or what?\"\n",
        "\n",
        "-9. Refused\n",
        "-8. Don’t know\n",
        "-4. Technical error\n",
        "0. No preference {VOL - video/phone only}\n",
        "1. Democrat\n",
        "2. Republican\n",
        "3. Independent\n",
        "5. Other party {SPECIFY}\n",
        "\n",
        "'''\n",
        "\n",
        "crosswalk_party_2 = pd.DataFrame({\n",
        "    \"Party_Numbers_(V201228)\": [-9, -8, -4, 0, 1, 2, 3, 5],\n",
        "    \"Party_Affiliation_(V201228)\": [\n",
        "        \"Refused\", \"Don't know\", \"Technical error\", \"No Preference\", \"Democrat\",\n",
        "        \"Republican\", \"Independent\", \"Other party\"\n",
        "    ]})\n",
        "\n",
        "sub_polarization = sub_polarization.merge(\n",
        "    crosswalk_party_2, left_on=\"V201228\", right_on=\"Party_Numbers_(V201228)\")\n"
      ],
      "id": "141f9cda",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will use two measures of polarization from the ANES data; each provides some amount of information that can be interpreted to indicate polarization to a certain extent, though both have their drawbacks.\n",
        "\n",
        "1. Share of Outliers - we create a series of functions that group respondents by party Democrats with conservative-leaning ideologies, and Republicans with liberal-leaning ones. \n"
      ],
      "id": "581ec67b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def find_share(df, state):\n",
        "    \"\"\"\n",
        "    Processes a subset of survey data for a specific state to identify and count party-affiliated respondents and ideological outliers.\n",
        "\n",
        "    Returns a subset of the input DataFrame, including new columns for:\n",
        "        - 'Party_Count': Counts of individuals affiliated with major parties.\n",
        "        - 'Outliers': Counts of ideological outliers within each party.\n",
        "\"\"\"\n",
        "    #subset by state\n",
        "    sub = df[df[\"US State 2\"] == state]\n",
        "    Party_People = [\"Democrat\", \"Republican\"]\n",
        "    Conservatives = [\"Slightly conservative\",\n",
        "    \"Conservative\",\n",
        "    \"Extremely conservative\"]\n",
        "    Liberals = [\"Extremely Liberal\",\n",
        "    \"Liberal\", \"Slightly Liberal\"]\n",
        "    #count of partisans\n",
        "    Party_Count = []\n",
        "    #count of entries that are Dem but conservative or Repub but liberal\n",
        "    Outlier_box = []\n",
        "    #get Party_Count\n",
        "    for index, entry in sub.iterrows():\n",
        "            if entry[\"Party_Affiliation_(V201228)\"] in Party_People:\n",
        "                    Party_Count.append(1)\n",
        "            else:\n",
        "                    Party_Count.append(0)\n",
        "    \n",
        "    for index, entry in sub.iterrows():\n",
        "            if (entry[\"Ideology_(V201200)\"] in Conservatives) & (entry[\"Party_Affiliation_(V201228)\"] == \"Democratic\"):\n",
        "                    Outlier_box.append(1)\n",
        "            elif (entry[\"Ideology_(V201200)\"] in Liberals) & (entry[\"Party_Affiliation_(V201228)\"] == \"Republican\"):\n",
        "                    Outlier_box.append(1)\n",
        "            else:\n",
        "                    Outlier_box.append(0)\n",
        "    \n",
        "    sub[\"Party_Count\"] = Party_Count\n",
        "    sub[\"Outliers\"] = Outlier_box\n",
        "    return sub\n",
        "        \n",
        "Z = find_share(sub_polarization, \"IL\")                     \n",
        "\n",
        "IL_Group = Z.groupby(\"Party_Affiliation_(V201228)\")[[\"Outliers\", \"Party_Count\"]].sum().reset_index()\n",
        "\n",
        "IL_Group[\"Percent_Outliers\"] =  IL_Group[\"Outliers\"] / sum(IL_Group[\"Party_Count\"])\n"
      ],
      "id": "97f42e41",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def seek_polar(df, state):\n",
        "    '''\n",
        "    Aggregates polarization data for a specific state, calculating the share of ideological outliers within party-affiliated populations.\n",
        "\n",
        "    '''\n",
        "    mod_df = find_share(df, state)\n",
        "    mod_df = mod_df.groupby(\n",
        "        \"Party_Affiliation_(V201228)\"\n",
        "        )[[\"Outliers\", \"Party_Count\"]].sum().reset_index()\n",
        "\n",
        "    mod_df[\"Percent_Outliers\"] =  mod_df[\"Outliers\"] / sum(mod_df[\"Party_Count\"])\n",
        "    return mod_df\n",
        "\n",
        "#Example with IL\n",
        "seek_polar(sub_polarization, \"IL\")\n"
      ],
      "id": "c9c4de6f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def find_share_state(df, state):\n",
        "    '''\n",
        "    Generates a modified subset of survey data for a given state, identifying partisans and ideological outliers.\n",
        "'''\n",
        "    #subset by state\n",
        "    sub = df[df[\"US State 2\"] == state]\n",
        "    Party_People = [\"Democrat\", \"Republican\"]\n",
        "    Conservatives = [\"Slightly Conservative\",\n",
        "    \"Conservative\",\n",
        "    \"Extremely Conservative\"]\n",
        "    Liberals = [\"Extremely Liberal\",\n",
        "    \"Liberal\", \"Slightly Liberal\"]\n",
        "    #count of partisans\n",
        "    Party_Count = []\n",
        "    #count of entries that are Dem but conservative or Repub but liberal\n",
        "    Outlier_box = []\n",
        "    #get Party_Count\n",
        "    for index, entry in sub.iterrows():\n",
        "            if entry[\"Party_Affiliation_(V201228)\"] in Party_People:\n",
        "                    Party_Count.append(1)\n",
        "            else:\n",
        "                    Party_Count.append(0)\n",
        "    \n",
        "    for index, entry in sub.iterrows():\n",
        "            if (entry[\"Ideology_(V201200)\"] in Conservatives) & (entry[\"Party_Affiliation_(V201228)\"] == \"Democratic\"):\n",
        "                    Outlier_box.append(1)\n",
        "            elif (entry[\"Ideology_(V201200)\"] in Liberals) & (entry[\"Party_Affiliation_(V201228)\"] == \"Republican\"):\n",
        "                    Outlier_box.append(1)\n",
        "            else:\n",
        "                    Outlier_box.append(0)\n",
        "    \n",
        "    sub[\"Party_Count\"] = Party_Count\n",
        "    sub[\"Outliers\"] = Outlier_box\n",
        "    return sub\n"
      ],
      "id": "d7b606d8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def find_share_nation(df):\n",
        "    '''\n",
        "    Processes survey data at the national level to identify party-affiliated respondents and ideological outliers.\n",
        "'''\n",
        "    Party_People = [\"Democrat\", \"Republican\"]\n",
        "    Conservatives = [\"Slightly Conservative\",\n",
        "                     \"Conservative\",\n",
        "                     \"Extremely Conservative\"]\n",
        "    Liberals = [\"Extremely Liberal\",\n",
        "                \"Liberal\", \"Slightly Liberal\"]\n",
        "    # count of partisans\n",
        "    Party_Count = []\n",
        "    # count of entries that are Dem but conservative or Repub but liberal\n",
        "    Outlier_box = []\n",
        "    # get Party_Count\n",
        "    for index, entry in df.iterrows():\n",
        "        if entry[\"Party_Affiliation_(V201228)\"] in Party_People:\n",
        "            Party_Count.append(1)\n",
        "        else:\n",
        "            Party_Count.append(0)\n",
        "    # get outlier count\n",
        "    for index, entry in df.iterrows():\n",
        "        if (entry[\"Ideology_(V201200)\"] in Conservatives) & (entry[\"Party_Affiliation_(V201228)\"] == \"Democratic\"):\n",
        "            Outlier_box.append(1)\n",
        "        elif (entry[\"Ideology_(V201200)\"] in Liberals) & (entry[\"Party_Affiliation_(V201228)\"] == \"Republican\"):\n",
        "            Outlier_box.append(1)\n",
        "        else:\n",
        "            Outlier_box.append(0)\n",
        "\n",
        "    df[\"Party_Count\"] = Party_Count\n",
        "    df[\"Outliers\"] = Outlier_box\n",
        "    return df"
      ],
      "id": "25bf55e0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def polar_table(df):\n",
        "    '''\n",
        "    Generates a summary table of polarization data, grouping by state to calculate the share of ideological outliers.\n",
        "    '''\n",
        "    mod_df = find_share_nation(df)\n",
        "    #make a grouped df that takes sum of each states' outliers and \n",
        "    #people who identify with a party\n",
        "    mod_df = mod_df.groupby(\"US State 2\")[\n",
        "        [\"Outliers\", \"Party_Count\"]\n",
        "        ].sum().reset_index()\n",
        "    mod_df[\"Percent_Outliers\"] =  mod_df[\"Outliers\"] / sum(mod_df[\"Party_Count\"])\n",
        "    return mod_df\n"
      ],
      "id": "2524a90a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "polar_by_party = polar_table(sub_polarization)\n",
        "\n",
        "#graphing percentages\n",
        "percent_graph_outliers = alt.Chart(polar_by_party).mark_bar().encode(\n",
        "    alt.X(\"US State 2\", title = \"State\"),\n",
        "    alt.Y(\"Percent_Outliers\", title = \"Outlier Share\"),\n",
        "    alt.Color(\"US State 2\")\n",
        ")\n",
        "\n",
        "#graphing sums\n",
        "sum_graph_outliers = alt.Chart(polar_by_party).mark_bar().encode(\n",
        "    alt.X(\"US State 2\", title = \"State\"),\n",
        "    alt.Y(\"Outliers\", title = \"Outlier Sum\"),\n",
        "    alt.Color(\"US State 2\")\n",
        ")"
      ],
      "id": "8a3e8435",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "'''\n",
        "In a paper on quantifying polarization written by Aaron Bramson et al (https://inferenceproject.yale.edu/sites/default/files/688938.pdf), the authors examine a range of polarization indicators. A relatively simple (and in some ways problematic) measurement is called spread, or dispersion- essentially the gap between the most extreme political positions.\n",
        "\n",
        "In the paper, Bramson et al. explain: \"Polarization in the sense of spread can be measured as the value of the agent with the highest belief value minus the value of the agent with the lowest belief value (sometimes called the ‘range’ of the data).\"\"\n",
        "\n",
        "We (imperfectly) approximate this using two more variables: V201206 and V201207. These ask respondents to position political parties on the political spectrum. We can select the most ideologically distant nodes on the personal ideology scale (extremely liberal and extremely conservative) and capture how far apart their conceptions of each party are,  on average, and then disaggregate by state.\n",
        "\n",
        "We will assign the different ideological positions to different points on a spectrum, namely:\n",
        "-3, -2, and -1 are \"Extremely Liberal\", \n",
        "\"Liberal\",  and \"Slightly Liberal\"; \n",
        "\n",
        "and:\n",
        "0 is \"Moderate; middle of the road\"; \n",
        "\n",
        "finally,\n",
        "1, 2, and 3 are \"Slightly conservative\",\n",
        "\"Conservative\" and \"Extremely conservative.\"\"\n",
        "\n",
        "We'll then compare average positions by state. For example, if the average \n",
        "extremely liberal respondent in Texas places Democrats at at -1 (slightly liberal) and the average for the extremely conservative respondents in -3 (extremely liberal), then the distance between the two is 4, meaning Texas would have a spread of 4 for this question.\n",
        "'''\n",
        "crosswalk_V201206 = pd.DataFrame({\n",
        "    #the dataset's scaled\n",
        "    \"Dem_Num_(V201206)\":[-9, -8, 1, 2, 3, 4, 5, 6, 7],\n",
        "    #the dataset's ideology\n",
        "    \"Dem_Ideology_(V201206)\": [\n",
        "        \"Refused\", \"Don't Know\", \"Extremely Liberal\",\n",
        "        \"Liberal\", \"Slightly Liberal\", \n",
        "        \"Moderate; middle of the road\",\n",
        "        \"Slightly Conservative\",\n",
        "        \"Conservative\",\n",
        "        \"Extremely Conservative\"\n",
        "    ],\n",
        "    #new values for comparison\n",
        "    \"Dem_Positioning(V201206)\":[0, 0, -3, -2, -1, 0, 1, 2, 3]\n",
        "    })\n",
        "\n",
        "#They're exactly the same\n",
        "crosswalk_V201207 = pd.DataFrame({\n",
        "    #the dataset's scale\n",
        "    \"Repub_Num_(V201207)\":[-9, -8, 1, 2, 3, 4, 5, 6, 7],\n",
        "    #the dataset's ideology\n",
        "    \"Repub_Ideology_(V201207)\": [\n",
        "        \"Refused\", \"Don't Know\", \"Extremely Liberal\",\n",
        "        \"Liberal\", \"Slightly Liberal\", \n",
        "        \"Moderate; middle of the road\",\n",
        "        \"Slightly Conservative\",\n",
        "        \"Conservative\",\n",
        "        \"Extremely Conservative\"\n",
        "    ],\n",
        "    #new values for comparison\n",
        "    \"Repub_Positioning(V201207)\":[0, 0, -3, -2, -1, 0, 1, 2, 3]\n",
        "    })\n",
        "\n",
        "#crosswalking V201206\n",
        "sub_polarization = sub_polarization.merge(crosswalk_V201206, left_on = \"V201206\", right_on = \"Dem_Num_(V201206)\")\n",
        "\n",
        "#crosswalking V201207\n",
        "sub_polarization = sub_polarization.merge(crosswalk_V201207, left_on = \"V201207\", right_on = \"Repub_Num_(V201207)\")\n",
        "\n",
        "#drop Dem_Num and Repub_Num for clarity (we'll be using the reassigned numbers)\n",
        "sub_polarization = sub_polarization.drop([\"Dem_Num_(V201206)\", \"Repub_Num_(V201207)\"], axis = 1)"
      ],
      "id": "ed69285a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "'''We use the Positioning columns to compare the average party position selections between the 2 extremes. '''\n",
        "\n",
        "#Step 1: First grouping\n",
        "\n",
        "#filter out all self-identifiers that aren't \"Extremely Liberal\"\n",
        "#or Extremely Conservative\n",
        "ex_polarization = sub_polarization[\n",
        "    (sub_polarization[\"Ideology_(V201200)\"] == \"Extremely Conservative\") | \n",
        "    (sub_polarization[\"Ideology_(V201200)\"] == \"Extremely Liberal\")\n",
        "    ]\n",
        "\n",
        "#filter out entries of Party Ideology Position that are \"Don't Know\" and \"Refused\"\n",
        "ex_polarization = ex_polarization[\n",
        "    (sub_polarization[\"Dem_Ideology_(V201206)\"] != \"Don't Know\") &\n",
        "    (sub_polarization[\"Dem_Ideology_(V201206)\"] != \"Refused\") &\n",
        "    (sub_polarization[\"Repub_Ideology_(V201207)\"] != \"Don't Know\") &\n",
        "    (sub_polarization[\"Repub_Ideology_(V201207)\"] != \"Refused\") \n",
        "    ]\n",
        "\n",
        "\n",
        "#make column for Liberal (i.e. Left tail) and Conservative (i.e. Right tail) \n",
        "Extreme_L_C = [\n",
        "    \"Liberal\" if row[\"Ideology_(V201200)\"] == \"Extremely Liberal\" else \"Conservative\" \n",
        "    for index, row in ex_polarization.iterrows()\n",
        "    ]\n",
        "\n",
        "#save to dataframe\n",
        "ex_polarization[\"Extreme_Position\"] = Extreme_L_C\n",
        "\n",
        "#groupby Extreme_Position and US State 2 and get average Dem and Repub positioning. Then save this to a df called position_groups\n",
        "position_groups = ex_polarization.groupby([\"US State 2\", \"Extreme_Position\"])[[\"Dem_Positioning(V201206)\", \"Repub_Positioning(V201207)\"]].mean().reset_index()"
      ],
      "id": "5c07c0f9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "'''\n",
        "Step 2: We use the variable position_groups to create a dataframe that has 4 columns:\n",
        "(1) The position Liberals give Democrats on the spectrum\n",
        "(2) the position Conservatives give Democrats on the spectrum\n",
        "(3) the position Liberals give Republicans on the spectrum\n",
        "(4) the position Conservatives give Republicans on the spectrum\n",
        "'''\n",
        "\n",
        "#Attribution: Asked ChatGPT for help fixing my list comprehension. Also asked ChatGPT how to flatten a multi-index column, which recommended ##source: https://www.w3resource.com/pandas/dataframe/dataframe-pivot.php\n",
        "\n",
        "\n",
        "#pivot on Extreme_Position\n",
        "pivot_position = position_groups.pivot(\n",
        "    index = \"US State 2\", \n",
        "    columns = \"Extreme_Position\", \n",
        "    values = [\"Dem_Positioning(V201206)\", \"Repub_Positioning(V201207)\"]\n",
        "    )\n",
        "\n",
        "#reset index to retrieve US State 2 variable from index\n",
        "pivot_position = pivot_position.reset_index()\n",
        "\n",
        "#Flatten multi-index by joining the upper and lower\n",
        "#levels of the multi-indexed columns together\n",
        "pivot_position.columns = ['_'.join(col).strip() for col in pivot_position.columns.values]\n",
        "\n",
        "#rename flattened columns\n",
        "pivot_position = pivot_position.rename(\n",
        "        columns = {\n",
        "            \"US State 2_\":\"US State 2\", \n",
        "            \"Dem_Positioning(V201206)_Conservative\":\"Dem_Position_C\",\n",
        "            \"Dem_Positioning(V201206)_Liberal\":\"Dem_Position_L\",\n",
        "            \"Repub_Positioning(V201207)_Conservative\":\"Repub_Position_C\",\n",
        "            \"Repub_Positioning(V201207)_Liberal\":\"Repub_Position_L\"\n",
        "        }\n",
        "    )\n"
      ],
      "id": "a7aeafd6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "'''Step 3: Now, we use those 4 columns to create the spread, meaning the absolute value of the difference betweeen:\n",
        "\n",
        "(1) The position Liberals give Democrats on the spectrum and the position Conservatives give Democrats on the spectrum\n",
        "\n",
        "(2) The position Liberals give Republicans on the spectrum and the position Conservatives give Republicans on the spectrum\n",
        "'''\n",
        "\n",
        "# Attribution: Used this article: https://www.w3resource.com/pandas/dataframe/dataframe-pivot.php\n",
        "# Asked ChatGPT how to flatten a multi-index column\n",
        "\n",
        "# capture spread variables\n",
        "pivot_position[\"Spread_Dem\"] = abs(\n",
        "    pivot_position[\"Dem_Position_C\"] -\n",
        "    pivot_position[\"Dem_Position_L\"]\n",
        ")\n",
        "\n",
        "pivot_position[\"Spread_Repub\"] = abs(\n",
        "    pivot_position[\"Repub_Position_C\"] -\n",
        "    pivot_position[\"Repub_Position_L\"]\n",
        ")"
      ],
      "id": "f1518909",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "'''\n",
        "Step 4: Now, we graph those differences and interpret these spreads as an indicator of polarization. We acknowledge that this is too simple an analysis to account for the full complexity of this kind of measurement, as polarization involves not just distance between extremes, but also clustering around them. We also acknowledge that our political scale assumes a linear ideological spectrum, which isn't always the case.\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "#Opinion on the position of the Democratic Party\n",
        "Democratic_Party_Spread_Graph = alt.Chart(pivot_position).mark_bar().encode(\n",
        "    alt.X(\"US State 2\", title = \"State\"),\n",
        "    alt.Y(\"Spread_Dem\", \n",
        "    title = \"Spread of Views\"),\n",
        "    alt.Color(\"US State 2\")\n",
        ").properties(title = alt.TitleParams(\"Spread of Views on Democratic Party Ideological Position\"))\n",
        "\n",
        "#Opinion on the position of the Republican Party\n",
        "Republican_Party_Spread_Graph = alt.Chart(pivot_position).mark_bar().encode(\n",
        "    alt.X(\"US State 2\", title = \"State\"),\n",
        "    alt.Y(\"Spread_Repub\", \n",
        "    title = \"Spread of Views\"),\n",
        "    alt.Color(\"US State 2\")\n",
        ").properties(title = alt.TitleParams(\"Spread of Views on Republican Party Ideological Position\"))"
      ],
      "id": "75ca6781",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "'''\n",
        "Step 5: We merge the two datasets together on \"US State 2\". Note that this merged dataset could be misleading, because some of the merged variables only apply to the \"extreme\" respondents in each state, and so it's not representative of the entire state's respondents' positioning of different parties. We've dropped those variables from the merge to try to account for this.\n",
        "'''\n",
        "merged_polarization = sub_polarization.merge(pivot_position, left_on = \"US State 2\", right_on = \"US State 2\", how = \"outer\")\n",
        "\n",
        "#drop variables that don't make sense when merged\n",
        "merged_polarization = merged_polarization.drop([\n",
        "    \"Dem_Position_C\", \"Dem_Position_L\",\n",
        "    \"Repub_Position_C\", \"Repub_Position_L\"], \n",
        "    axis = 1\n",
        "    )"
      ],
      "id": "9694d639",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "'''Step 6: We merge the AmeriCorps CEV/VCL data with the spread data so far'''\n",
        "\n",
        "#remove 'Not in Universe', 'No Answer', 'Refused'\n",
        "#from cev_all_2021_filter\n",
        "\n",
        "Non_Number_List = [\n",
        "    'Not in Universe', np.nan, \"Do Not Know\",\n",
        "    'No Answer', 'Refused']\n",
        "\n",
        "cev_all_2021_all_number = cev_all_2021_filter[\n",
        "    ~cev_all_2021_filter[\"Hours_Spent_Volunteering\"].isin(Non_Number_List)\n",
        "    ]\n",
        "\n",
        "#group volunteer rates by state\n",
        "group_cev = cev_all_2021_all_number.groupby(\n",
        "    \"US State\"\n",
        "    )[[\"Hours_Spent_Volunteering\", \n",
        "    \"political_engagement_score\"]].mean().reset_index()\n",
        "\n",
        "main_group = group_cev.merge(\n",
        "    pivot_position, left_on = \"US State\", right_on = \"US State 2\"\n",
        ")"
      ],
      "id": "812dbd12",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "'''\n",
        "Step 7: We create a function for viewing Political Engagement alongside spread, one generating a table with 2 states for comparison, and another 2 \n",
        "returning graphs\n",
        "'''\n",
        "\n",
        "#return table\n",
        "def engagement_spread_table(df, state_1, state_2):\n",
        "        sub = df[\n",
        "            (df[\"US State\"] == state_1) |\n",
        "            (df[\"US State\"] == state_2)]\n",
        "        sub = sub.filter([\"US State\", \"political_engagement_score\", \"Spread_Dem\", \"Spread_Repub\"])\n",
        "        return sub\n",
        "\n",
        "#return graph with Democratic positioning \n",
        "def engagement_spread_graph_D(df, column):\n",
        "        graph = alt.Chart(df).mark_bar().encode(\n",
        "        alt.X(\"US State 2\", title = \"State\", sort = \"-y\"),\n",
        "        alt.Y(\"Spread_Dem\", title = \"Spread of Extreme Views\"),\n",
        "         alt.Color(\n",
        "            column, \n",
        "            scale = alt.Scale(range = [\"lightblue\", \"darkblue\"])\n",
        "            )\n",
        "        ).properties(\n",
        "            title = alt.TitleParams(\n",
        "                \"Spread of Views on Democratic Party Ideological Position\"\n",
        "                )\n",
        "            )\n",
        "        return graph\n",
        "\n",
        "#return graph with Republican positioning \n",
        "def engagement_spread_graph_R(df, column):    \n",
        "        graph = alt.Chart(df).mark_bar().encode(\n",
        "        alt.X(\"US State 2\", title = \"State\", sort = \"-y\"),\n",
        "        alt.Y(\"Spread_Repub\", title = \"Spread of Extreme Views\"),\n",
        "        alt.Color(\n",
        "            column, \n",
        "            scale = alt.Scale(range = [\"lightblue\", \"darkblue\"]),\n",
        "            )\n",
        "        ).properties(\n",
        "            title = alt.TitleParams(\n",
        "                \"Spread of Views on Republican Party Ideological Position\"\n",
        "                )\n",
        "            )\n",
        "        return graph"
      ],
      "id": "8e5267e1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Below is an example of using our function to generate a political engagement score for different states: \n",
        "\n",
        "#sample static table with \n",
        "Sample_Table = engagement_spread_table(main_group, \"IL\", \"OR\")\n",
        "\n",
        "print(Sample_Table)"
      ],
      "id": "85b16709",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#And below are sample static graphs on Democratic and Republican positions:\n",
        "\n",
        "#using average political engagement\n",
        "Dem_Graph_Spread_1 = engagement_spread_graph_D(main_group, \"political_engagement_score\")\n",
        "\n",
        "#using average volunteer hours\n",
        "Dem_Graph_Spread_2 = engagement_spread_graph_D(main_group, \"Hours_Spent_Volunteering\")\n",
        "\n",
        "Dem_Graph_Spread_1.show()\n",
        "Dem_Graph_Spread_1.save('dem_graph_spread.png', format='png')\n",
        "\n",
        "Dem_Graph_Spread_2.show()\n",
        "Dem_Graph_Spread_2.save('dem_graph_spread_2.png', format='png')"
      ],
      "id": "2d8794fd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#using average political engagement\n",
        "Repub_Graph_Spread_1 = engagement_spread_graph_R(main_group, \"political_engagement_score\")\n",
        "\n",
        "#using average volunteer hours\n",
        "Repub_Graph_Spread_2 = engagement_spread_graph_R(main_group, \"Hours_Spent_Volunteering\")\n",
        "\n",
        "Repub_Graph_Spread_1.show() \n",
        "Repub_Graph_Spread_1.save('repub_graph_spread.png', format='png')\n",
        "\n",
        "\n",
        "Repub_Graph_Spread_2.show()\n",
        "Repub_Graph_Spread_2.save('repub_graph_spread_2.png', format='png')"
      ],
      "id": "66afcd84",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below is a atatic graph of ideological position in the US nationally as of 2020:\n"
      ],
      "id": "713551cb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "alt.data_transformers.enable(\"vegafusion\")\n",
        "#create list for graph to sort on \n",
        "sorting_list = [\n",
        "        \"Refused\", \"Don't Know\", \"Extremely Liberal\",\n",
        "        \"Liberal\", \"Slightly Liberal\", \n",
        "        \"Moderate; middle of the road\",\n",
        "        \"Slightly Conservative\",\n",
        "        \"Conservative\",\n",
        "        \"Extremely Conservative\",\n",
        "        \"Haven’t thought much about this\"\n",
        "    ]\n",
        "\n",
        "#filter out non-responses\n",
        "global_non_response_list = [\n",
        "    \"Haven’t thought much about this\",\n",
        "    \"Refused\", \"Don't Know\"\n",
        "    ]\n",
        "\n",
        "local_filter = sub_polarization[\n",
        "    ~sub_polarization[\"Ideology_(V201200)\"].isin(global_non_response_list)\n",
        "]\n",
        "\n",
        "Ideological_Position_US = alt.Chart(local_filter).mark_bar().encode(\n",
        "    alt.X(\n",
        "        \"Ideology_(V201200):N\", \n",
        "        title = \"Ideological Position\",\n",
        "        sort = sorting_list),\n",
        "    alt.Y(\"Observations\", title = \"Number of Respondents\"),\n",
        "    alt.Color(\"Ideology_(V201200)\", sort = sorting_list)\n",
        ").properties(title = alt.TitleParams(\n",
        "            f\"Ideological Position in the U.S.\"\n",
        "        ))\n",
        "\n",
        "Ideological_Position_US.show()\n",
        "\n",
        "#Note: We removed non-responses, likely creating a bias in the relative size of the remaining groups (it's difficult to predict the direction of said bias, however.)"
      ],
      "id": "6f7bb7a5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Additionally, below is a sample static graph of ideological position by state, using IL as an example:\n",
        "\n",
        "def ideology_by_state(df, state):\n",
        "        #filter out non-responses\n",
        "        non_response_list = [\n",
        "            \"Haven’t thought much about this\", \n",
        "            \"Refused\", \"Don't Know\"\n",
        "            ]\n",
        "        sub = df[\n",
        "            ~df[\"Ideology_(V201200)\"].isin(non_response_list)\n",
        "            ]\n",
        "        #filter for the selected state\n",
        "        sub = sub[sub[\"US State 2\"] == state]\n",
        "        #create list for graph to sort on \n",
        "        sorting_list = [\n",
        "        \"Extremely Liberal\",\n",
        "        \"Liberal\", \"Slightly Liberal\", \n",
        "        \"Moderate; middle of the road\",\n",
        "        \"Slightly Conservative\",\n",
        "        \"Conservative\",\n",
        "        \"Extremely Conservative\"\n",
        "        ]\n",
        "        graph = alt.Chart(sub).mark_bar().encode(\n",
        "            alt.X(\n",
        "                \"Ideology_(V201200):N\", \n",
        "                title = \"Ideological Position\",\n",
        "                sort = sorting_list\n",
        "                ),\n",
        "            alt.Y(\"count():Q\", title = \"Number of Respondents\"),\n",
        "            alt.Color(\"Ideology_(V201200):N\", sort = sorting_list)\n",
        "        ).properties(title = alt.TitleParams(\n",
        "            f\"Ideological Position in {state}\"\n",
        "        ))\n",
        "        return graph\n",
        "\n",
        "#Example for Illinois\n",
        "Ideological_Position_IL = ideology_by_state(sub_polarization, \"IL\")\n",
        "\n",
        "Ideological_Position_IL.show()"
      ],
      "id": "fa026644",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Lastly, we will use the merged AmeriCorps and ANES data to plot a correlation between volunteer hours and political engagement:\n",
        "\n",
        "Correlation_Graph = alt.Chart(main_group).mark_circle().encode(\n",
        "    alt.X(\"Hours_Spent_Volunteering\", title=\"Average Volunteer Hours\"),\n",
        "    alt.Y(\"political_engagement_score\", title=\"Average Political Engagement Score\").scale(\n",
        "        domain=(\n",
        "            main_group[\"political_engagement_score\"].min() - 3,\n",
        "            main_group[\"political_engagement_score\"].max() + 3\n",
        "        )\n",
        "    ),\n",
        "    alt.Color(\"US State 2\")\n",
        ").properties(title=alt.TitleParams(\n",
        "    \"Correlation between volunteer hours and political engagement\"\n",
        "))\n",
        "\n",
        "Correlation_Graph.show()"
      ],
      "id": "fe66d5be",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Below is the exploratory data analysis (h/t Justine)\n",
        "\n",
        "# Basic plot to show Frequency of Volunteering Categories\n",
        "\n",
        "filtered_data = cev_all_2021_filter[\n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Not in Universe\") &\n",
        "    (cev_all_2021_filter['Volunteering_Frequency'].notna()) &\n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"No Answer\") &\n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Refusal\") &\n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Do Not Know\")\n",
        "]\n",
        "\n",
        "frequency_counts = filtered_data['Volunteering_Frequency'].value_counts(\n",
        ").reset_index()\n",
        "frequency_counts = pd.DataFrame(frequency_counts)\n",
        "\n",
        "frequency_counts.columns = ['Volunteering_Frequency', 'Frequency']\n",
        "\n",
        "chart = alt.Chart(frequency_counts).mark_bar().encode(\n",
        "    y=alt.Y('Volunteering_Frequency:O', title='Frequency Count'),\n",
        "    x=alt.X('Frequency:Q', title='Frequency Count'),\n",
        "    color=alt.Color('Frequency:Q', scale=alt.Scale(\n",
        "        scheme='blues'), title='Volunteering Frequency'),\n",
        "    tooltip=['Volunteering_Frequency', 'Frequency']\n",
        ").properties(\n",
        "    title='Frequency of Volunteering Categories (Excluding \"No Answer\")',\n",
        "    width=550,\n",
        "    height=200\n",
        ")\n",
        "\n",
        "chart.show()\n",
        "chart.save('volunteer_frequency.png', format='png')"
      ],
      "id": "f3bd8ce0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot to show Volunteering Frequency based on if one volunteered last year (2020)\n",
        "\n",
        "volunteered_last_year = cev_all_2021_filter[\n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Not in Universe\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'].notna()) &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"No Answer\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Refusal\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Do Not Know\") &  \n",
        "    (cev_all_2021_filter['Volunteered_Past_Year'] == \"Yes\")\n",
        "]\n",
        "\n",
        "did_not_volunteer_last_year = cev_all_2021_filter[\n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Not in Universe\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'].notna()) &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"No Answer\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Refusal\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Do Not Know\") &  \n",
        "    (cev_all_2021_filter['Volunteered_Past_Year'] == \"No\")\n",
        "]\n",
        "\n",
        "volunteered_counts = volunteered_last_year['Volunteering_Frequency'].value_counts().reset_index()\n",
        "volunteered_counts.columns = ['Volunteering_Frequency', 'Frequency']\n",
        "volunteered_counts['Volunteered_Past_Year'] = 'Yes'\n",
        "\n",
        "did_not_volunteer_counts = did_not_volunteer_last_year['Volunteering_Frequency'].value_counts().reset_index()\n",
        "did_not_volunteer_counts.columns = ['Volunteering_Frequency', 'Frequency']\n",
        "did_not_volunteer_counts['Volunteered_Past_Year'] = 'No'\n",
        "\n",
        "combined_counts = pd.concat([volunteered_counts, did_not_volunteer_counts])\n",
        "\n",
        "chart = alt.Chart(combined_counts).mark_bar().encode(\n",
        "    y=alt.Y('Volunteering_Frequency:O', title='Volunteering Frequency'),  \n",
        "    x=alt.X('Frequency:Q', title='Count'),  \n",
        "    color=alt.Color('Volunteered_Past_Year:N', title='Volunteered Last Year', legend=alt.Legend(title=\"Volunteered Last Year\")),  \n",
        "    tooltip=['Volunteering_Frequency', 'Frequency', 'Volunteered_Past_Year']\n",
        ").properties(\n",
        "    title='Volunteering Frequency for Those Who Volunteered Last Year vs. Those Who Did Not',\n",
        "    width=600,\n",
        "    height=200\n",
        ")\n",
        "\n",
        "chart.show()\n",
        "chart.save('if_volunteered_last_year.png', format='png')"
      ],
      "id": "4061354e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# If they voted or not in the local election with no orange\n",
        "\n",
        "\n",
        "#filtered if did vote\n",
        "volunteered_last_year = cev_all_2021_filter[\n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Not in Universe\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'].notna()) &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"No Answer\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Refusal\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Do Not Know\") &  \n",
        "    (cev_all_2021_filter['Voted_In_Local_Election'] == \"Yes\")\n",
        "]\n",
        "\n",
        "# Filter data for those who did not vote\n",
        "did_not_volunteer_last_year = cev_all_2021_filter[\n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Not in Universe\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'].notna()) &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"No Answer\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Refusal\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Do Not Know\") &  \n",
        "    (cev_all_2021_filter['Voted_In_Local_Election'] == \"No\")\n",
        "]\n",
        "\n",
        "volunteered_counts = volunteered_last_year['Volunteering_Frequency'].value_counts().reset_index()\n",
        "volunteered_counts.columns = ['Volunteering_Frequency', 'Frequency']\n",
        "volunteered_counts['Voted_In_Local_Election'] = 'Yes'\n",
        "\n",
        "did_not_volunteer_counts = did_not_volunteer_last_year['Volunteering_Frequency'].value_counts().reset_index()\n",
        "did_not_volunteer_counts.columns = ['Volunteering_Frequency', 'Frequency']\n",
        "did_not_volunteer_counts['Voted_In_Local_Election'] = 'No'\n",
        "\n",
        "combined_counts = pd.concat([volunteered_counts, did_not_volunteer_counts])\n",
        "\n",
        "chart = alt.Chart(combined_counts).mark_bar().encode(\n",
        "    y=alt.Y('Volunteering_Frequency:O', title='Volunteering Frequency'),  \n",
        "    x=alt.X('Frequency:Q', title='Count'),  \n",
        "    color=alt.Color('Voted_In_Local_Election:N', title='Voted in Local Election', scale=alt.Scale(domain=['Yes', 'No'], range=['blue', 'red']), legend=alt.Legend(title=\"Voted\")),  \n",
        "    tooltip=['Volunteering_Frequency', 'Frequency', 'Voted_In_Local_Election']\n",
        ").properties(\n",
        "    title='Volunteering Frequency for Those Who Voted vs. Those Who Did Not',\n",
        "    width=600,\n",
        "    height=200\n",
        ")\n",
        "\n",
        "chart.show()\n",
        "chart.save('if_voted_in_local_election.png', format='png')"
      ],
      "id": "a30c6975",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# What is the correlation or relationship between volunteering frequency, news consumption and voting? \n",
        "\n",
        "\n",
        "volunteering_frequencies = cev_all_2021_filter[\n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Not in Universe\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'].notna()) &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"No Answer\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Refusal\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Do Not Know\")\n",
        "]\n",
        "\n",
        "if_voted = volunteering_frequencies.loc[volunteering_frequencies['Voted_In_Local_Election'].isin(['Yes', 'No'])]\n",
        "\n",
        "News_Consumption = if_voted.loc[\n",
        "    if_voted['Frequency_Of_News_Consumption'].notna() & \n",
        "    ~if_voted['Frequency_Of_News_Consumption'].isin(['Basically Every Day', 'Refusal', 'Do Not Know', 'No Answer'])\n",
        "]\n",
        "\n",
        "News_Consumption_map = {\n",
        "    'A Few Times a Week': 'blue',       \n",
        "    'Not at All': 'green',              \n",
        "    'A Few Times a Month': 'orange',    \n",
        "    'Once A Month': 'red',   \n",
        "    'Less Than Once a Month': 'purple'              \n",
        "}\n",
        "\n",
        "News_Consumption['News_Consumption_Color'] = News_Consumption['Frequency_Of_News_Consumption'].map(News_Consumption_map)\n",
        "\n",
        "counts = News_Consumption.groupby(\n",
        "    ['Volunteering_Frequency', 'Voted_In_Local_Election', 'Frequency_Of_News_Consumption', 'News_Consumption_Color']\n",
        ").size().reset_index(name='Frequency')\n",
        "\n",
        "chart = alt.Chart(counts).mark_point(filled=True).encode(\n",
        "    y=alt.Y('Frequency_Of_News_Consumption:N', title='News Consumption Frequency'),  \n",
        "    x=alt.X('Frequency:Q', title='Count'),  \n",
        "    shape=alt.Shape('Voted_In_Local_Election:N',  \n",
        "                    title='Voted in Local Election',\n",
        "                    scale=alt.Scale(domain=['Yes', 'No'], range=['circle', 'square'])),  \n",
        "    color=alt.Color('Volunteering_Frequency:N',  \n",
        "                    title='Volunteering Frequency',\n",
        "                    scale=alt.Scale(domain=['Not at All', 'A Few Times a Month', 'A Few Times a Week', 'Once a Month', 'Less Than Once a Month'],\n",
        "                                    range=['blue', 'green', 'orange', 'red', 'purple'])),  \n",
        "    size=alt.SizeValue(100),\n",
        "    tooltip=['Volunteering_Frequency', 'Frequency', 'Voted_In_Local_Election', 'Frequency_Of_News_Consumption']  \n",
        ").properties(\n",
        "    title='News Consumption vs. Volunteering Frequency with Voting Behavior',\n",
        "    width=600,\n",
        "    height=200\n",
        ")\n",
        "\n",
        "chart.show()\n",
        "chart.save('news_consumption_volunteering_correlation.png', format='png')"
      ],
      "id": "a214bf57",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# If consumed news basically everyday, what is your voting frequency \n",
        "\n",
        "volunteering_frequencies = cev_all_2021_filter[\n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Not in Universe\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'].notna()) &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"No Answer\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Refusal\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Do Not Know\")\n",
        "]\n",
        "\n",
        "if_voted = volunteering_frequencies.loc[volunteering_frequencies['Voted_In_Local_Election'].isin(['Yes', 'No'])]\n",
        "\n",
        "News_Consumption_daily = if_voted.loc[\n",
        "    if_voted['Frequency_Of_News_Consumption'] == 'Basically Every Day'  \n",
        "]\n",
        "counts = News_Consumption_daily.groupby(\n",
        "    ['Volunteering_Frequency', 'Voted_In_Local_Election']\n",
        ").size().reset_index(name='Frequency')\n",
        "\n",
        "\n",
        "chart = alt.Chart(counts).mark_bar().encode(\n",
        "    x=alt.X('Volunteering_Frequency:N', title='Volunteering Frequency', \n",
        "            axis=alt.Axis(labelAngle=45)),  \n",
        "    y=alt.Y('Frequency:Q', title='Count'),  \n",
        "    color=alt.Color('Voted_In_Local_Election:N',  \n",
        "                    scale=alt.Scale(domain=['Yes', 'No'], range=['blue', 'orange']),\n",
        "                    title='Voted in Local Election'),\n",
        "\n",
        "    tooltip=['Volunteering_Frequency', 'Frequency', 'Voted_In_Local_Election']  \n",
        ").properties(\n",
        "    title='Volunteering Frequency vs. Voting Behavior',\n",
        "    width=300,\n",
        "    height=300\n",
        ")\n",
        "\n",
        "chart.show()\n",
        "chart.save('volunteering_vs_voting_news_daily.png', format='png')"
      ],
      "id": "30bcbd55",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Does the consumption of news impact hours spent volunteering?\n",
        "\n",
        "filtered_data = volunteering_frequencies[\n",
        "    (volunteering_frequencies['Frequency_Of_News_Consumption'].notna()) & \n",
        "    ~volunteering_frequencies['Frequency_Of_News_Consumption'].isin(['Basically Every Day', 'Refusal', 'Do Not Know', 'No Answer']) & \n",
        "    (volunteering_frequencies['Hours_Spent_Volunteering'].notna()) & \n",
        "    ~volunteering_frequencies['Hours_Spent_Volunteering'].isin(['Not in Universe', 'Do Not Know', 'Refused'])\n",
        "]\n",
        "filtered_data = filtered_data[filtered_data['Hours_Spent_Volunteering'] <= 250]\n",
        "\n",
        "chart = alt.Chart(filtered_data).mark_boxplot(extent='min-max').encode(\n",
        "    x=alt.X('Frequency_Of_News_Consumption:N', title='News Consumption Frequency', sort=None),  \n",
        "    y=alt.Y('Hours_Spent_Volunteering:Q', \n",
        "            title='Hours Spent Volunteering', \n",
        "            scale=alt.Scale(domain=[0, 250])), \n",
        "    tooltip=['Frequency_Of_News_Consumption', 'Hours_Spent_Volunteering']  \n",
        ").properties(\n",
        "    title='Boxplot of Hours Spent Volunteering by News Consumption Frequency',\n",
        "    width=200,  \n",
        "    height=600  \n",
        ")\n",
        "\n",
        "chart.show()\n",
        "chart.save('boxplot_news_consumption_vs_volunteering_hours.png', format='png')"
      ],
      "id": "490a4d4e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# preparing some data, to list the average number of hours volunteered by state\n",
        "\n",
        "filtered_data = volunteering_frequencies[\n",
        "    (volunteering_frequencies['Hours_Spent_Volunteering'].notna()) & \n",
        "    ~volunteering_frequencies['Hours_Spent_Volunteering'].isin(['Not in Universe', 'Do Not Know', 'Refusal'])\n",
        "]\n",
        "\n",
        "filtered_data['Hours_Spent_Volunteering'] = pd.to_numeric(filtered_data['Hours_Spent_Volunteering'], errors='coerce')\n",
        "\n",
        "filtered_data = filtered_data[filtered_data['Hours_Spent_Volunteering'].notna()]\n",
        "\n",
        "average_hours_per_state = filtered_data.groupby('US State')['Hours_Spent_Volunteering'].mean().reset_index()\n",
        "\n",
        "average_hours_per_states = average_hours_per_state.sort_values(by='Hours_Spent_Volunteering', ascending=False)"
      ],
      "id": "e3ddb387",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# using the above data to show the top and bottom 5 states when it comes to average hours of volunteering\n",
        "\n",
        "top_bottom_states = pd.concat([average_hours_per_state.nlargest(5, 'Hours_Spent_Volunteering'), average_hours_per_state.nsmallest(5, 'Hours_Spent_Volunteering')])\n",
        "\n",
        "scatter_plot = alt.Chart(top_bottom_states).mark_point(size=100, color='blue').encode(\n",
        "    x=alt.X('US State:N', title='US State', sort='-y'),  \n",
        "    y=alt.Y('Hours_Spent_Volunteering:Q', title='Average Hours Spent Volunteering')  \n",
        ")\n",
        "chart = scatter_plot + top_bottom_labels\n",
        "\n",
        "chart = chart.properties(\n",
        "    title='Top 5 and Bottom 5 States by Average Hours Spent Volunteering',\n",
        "    width=400,   \n",
        "    height=00   \n",
        ").configure_axisY(\n",
        "    labelAngle=0  \n",
        ").configure_axisX(\n",
        "    labelAngle=45  \n",
        ")\n",
        "chart.show()\n",
        "chart.save('top_bottom_5_states_avg_volunteering.png', format='png')"
      ],
      "id": "d6e2082d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# the following chart is total number of volunteers per state and stacked by volunteer frequency\n",
        "filtered_data = volunteering_frequencies.dropna(subset=['US State'])\n",
        "\n",
        "aggregated_data = filtered_data.groupby(['US State', 'Volunteering_Frequency']).size().reset_index(name='Count')\n",
        "\n",
        "total_counts = aggregated_data.groupby('US State')['Count'].sum().reset_index(name='Total_Count')\n",
        "sorted_states = total_counts.sort_values(by='Total_Count', ascending=False)\n",
        "\n",
        "aggregated_data_sorted = pd.merge(aggregated_data, sorted_states[['US State']], on='US State', how='inner')\n",
        "\n",
        "chart = alt.Chart(aggregated_data_sorted).mark_bar().encode(\n",
        "    x=alt.X('US State:N', title='State', sort=sorted_states['US State'].tolist()),  \n",
        "    y=alt.Y('Count:Q', title='Count of Volunteers per State'),  \n",
        "    color='Volunteering_Frequency:N',  \n",
        "    tooltip=['US State', 'Volunteering_Frequency', 'Count']  \n",
        ").properties(\n",
        "    title='Volunteering Frequency by State (Sorted by Total Count)',\n",
        "    width=600,\n",
        "    height=400\n",
        ")\n",
        "\n",
        "text = chart.mark_text(\n",
        "    align='center',\n",
        "    baseline='middle',\n",
        "    dy=-5,  \n",
        "    size=6\n",
        ").encode(\n",
        "    text='Count:Q'  \n",
        ")\n",
        "\n",
        "final_chart = chart + text\n",
        "final_chart"
      ],
      "id": "295a1cb3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "final_chart.save('number_volunteers_per_state.png', format='png')"
      ],
      "id": "bee0b566",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# chart depicted share of people who boycotted based on volunteering frequency\n",
        "#boycott chart\n",
        "#filtered if did vote\n",
        "volunteered_last_year = cev_all_2021_filter[\n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Not in Universe\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'].notna()) &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"No Answer\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Refusal\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Do Not Know\") & \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Not at All\") & \n",
        "    (cev_all_2021_filter['Boycott_Based_On_Values'] == \"Yes\")\n",
        "]\n",
        "\n",
        "# Filter data for those who did not vote\n",
        "did_not_volunteer_last_year = cev_all_2021_filter[\n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Not in Universe\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'].notna()) &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"No Answer\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Refusal\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Do Not Know\") &\n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Not at All\") &  \n",
        "    (cev_all_2021_filter['Boycott_Based_On_Values'] == \"No\")\n",
        "]\n",
        "\n",
        "volunteered_counts = volunteered_last_year['Volunteering_Frequency'].value_counts().reset_index()\n",
        "volunteered_counts.columns = ['Volunteering_Frequency', 'Frequency']\n",
        "volunteered_counts['Boycott_Based_On_Values'] = 'Yes'\n",
        "\n",
        "did_not_volunteer_counts = did_not_volunteer_last_year['Volunteering_Frequency'].value_counts().reset_index()\n",
        "did_not_volunteer_counts.columns = ['Volunteering_Frequency', 'Frequency']\n",
        "did_not_volunteer_counts['Boycott_Based_On_Values'] = 'No'\n",
        "\n",
        "combined_counts = pd.concat([volunteered_counts, did_not_volunteer_counts])\n",
        "\n",
        "chart = alt.Chart(combined_counts).mark_bar().encode(\n",
        "    y=alt.Y('Volunteering_Frequency:O', title='Volunteering Frequency'),  \n",
        "    x=alt.X('Frequency:Q', title='Count'),  \n",
        "    color=alt.Color('Boycott_Based_On_Values:N', title='Boycotted', scale=alt.Scale(domain=['Yes', 'No'], range=['blue', 'purple']), legend=alt.Legend(title=\"Boycotted\")),  \n",
        "    tooltip=['Volunteering_Frequency', 'Frequency', 'Boycott_Based_On_Values']\n",
        ").properties(\n",
        "    title='Volunteering Frequency for Those Who Boycotted based on their Values or not',\n",
        "    width=600,\n",
        "    height=400\n",
        ")\n",
        "\n",
        "chart.show()\n",
        "chart.save('boycotted.png', format='png')"
      ],
      "id": "ef1555ec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# same as above except now if person contacted public official"
      ],
      "id": "28611830"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "volunteered_last_year = cev_all_2021_filter[\n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Not in Universe\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'].notna()) &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"No Answer\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Refusal\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Do Not Know\") &  \n",
        "    (cev_all_2021_filter['Contacted_Public_Official'] == \"Yes\")\n",
        "]\n",
        "\n",
        "# Filter data for those who did not vote\n",
        "did_not_volunteer_last_year = cev_all_2021_filter[\n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Not in Universe\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'].notna()) &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"No Answer\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Refusal\") &  \n",
        "    (cev_all_2021_filter['Volunteering_Frequency'] != \"Do Not Know\") &  \n",
        "    (cev_all_2021_filter['Contacted_Public_Official'] == \"No\")\n",
        "]\n",
        "\n",
        "volunteered_counts = volunteered_last_year['Volunteering_Frequency'].value_counts().reset_index()\n",
        "volunteered_counts.columns = ['Volunteering_Frequency', 'Frequency']\n",
        "volunteered_counts['Contacted_Public_Official'] = 'Yes'\n",
        "\n",
        "did_not_volunteer_counts = did_not_volunteer_last_year['Volunteering_Frequency'].value_counts().reset_index()\n",
        "did_not_volunteer_counts.columns = ['Volunteering_Frequency', 'Frequency']\n",
        "did_not_volunteer_counts['Contacted_Public_Official'] = 'No'\n",
        "\n",
        "combined_counts = pd.concat([volunteered_counts, did_not_volunteer_counts])\n",
        "\n",
        "chart = alt.Chart(combined_counts).mark_bar().encode(\n",
        "    y=alt.Y('Volunteering_Frequency:O', title='Volunteering Frequency'),  \n",
        "    x=alt.X('Frequency:Q', title='Count'),  \n",
        "    color=alt.Color('Contacted_Public_Official:N', title='Contacted Elected Official', scale=alt.Scale(domain=['Yes', 'No'], range=['green', 'brown']), legend=alt.Legend(title=\"Called\")),  \n",
        "    tooltip=['Volunteering_Frequency', 'Frequency', 'Contacted_Public_Official']\n",
        ").properties(\n",
        "    title='Volunteering Frequency for Those Who Called their Public Official',\n",
        "    width=400,\n",
        "    height=200\n",
        ")\n",
        "\n",
        "chart.show()\n",
        "chart.save('contacted.png', format='png')"
      ],
      "id": "8b93f0d6",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/charleshuang/Documents/GitHub/student30538/problem_sets/final_project/venv/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}