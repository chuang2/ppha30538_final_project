{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"30538 Final Project: Reproducible Research - Volunteerism, Engagement, and Polarization in the U.S.\"\n",
        "author: \"Andrew White, Charles Huang, Justine Silverstein\" \n",
        "date: \"December 7, 2024\"\n",
        "format: pdf\n",
        "execute:\n",
        "  echo: false\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "1. Data wrangling (25%)\n"
      ],
      "id": "3e2e0b65"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# General\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualization \n",
        "import altair as alt\n",
        "\n",
        "# Geospatial data handling\n",
        "import geopandas as gpd\n",
        "\n",
        "# shiny framework\n",
        "from shiny import App, ui, render\n",
        "\n",
        "#for spatial data\n",
        "from us import states"
      ],
      "id": "477a2876",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Background\n",
        "\n",
        "This project began as a shared interest in trends behind volunteering rates in America, as two of our members (Justine and Charles) are AmeriCorps alumni.\n",
        "\n",
        "For the past few years, concerns about the American public's increasing rates of isolation, decreasing lack of civic engagement and faith in institutions, and greater rates of political polarization have been prominent in the news and media. Our personal experiences with AmeriCorps and volunteering have taught us that volunteering can be effective at reducing isolation, increasing civic engagement/community awareness, and decreasing negative polarization towards \"the other side\". However, is volunteering a legitimate part of a public policy solution to these issues, or is it just a red herring?\n",
        "\n",
        "Our research questions were: \n",
        "1. What is the current state of volunteerism, political engagement and polarization in America? \n",
        "2. What factors make people more likely to volunteer or be civically engaged?\n",
        "\n",
        "\n",
        "# Data Importing/Cleaning\n",
        "\n",
        "Our datasets for this project were:\n",
        "\n",
        "1. AmeriCorps CEV (Civic Engagement and Volunteering Supplement) for 2021\n",
        "2. U.S. Census Bureau Volunteering and Civic Life Supplement - September 2021\n",
        "3. ANES (American National Election Studies) Time Series Data, 2020\n",
        "\n",
        "#1 and #2 primarily contain respondent information about volunteering and measures of civic engagement, while #3 contains information on political affiliation and polarization.\n",
        "\n",
        "We are importing the data from the AmeriCorps and ANES websites. Because the datasets are over 100 MB, we include a Google Drive link here:\n",
        "\n",
        "https://drive.google.com/drive/folders/1PUTN2pyh78MLoK0RVtGnf1ZwiM1BAAuV?usp=sharing\n"
      ],
      "id": "92c7511b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Google Drive link for data: https://drive.google.com/drive/folders/1PUTN2pyh78MLoK0RVtGnf1ZwiM1BAAuV?usp=sharing\n",
        "\n",
        "\n",
        "cev_2021_raw = pd.read_csv(\"/Users/charleshuang/Documents/GitHub/student30538/problem_sets/final_project/data/2021_CEV__Current_Population_Survey_Civic_Engagement_and_Volunteering_Supplement_20241031.csv\", encoding = 'utf-8')\n",
        "\n",
        "vcl_supplement_raw = pd.read_csv(\"/Users/charleshuang/Documents/GitHub/student30538/problem_sets/final_project/data/sep21pub.csv\")\n",
        "\n",
        "polarization = pd.read_csv(\"/Users/charleshuang/Documents/GitHub/student30538/problem_sets/final_project/data/anes_timeseries_2020_csv_20220210.csv\")"
      ],
      "id": "21dbe4bb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data cleaning - CEV/VCL data \n",
        "\n",
        "As there are over 400 variables in the CEV and VCL data, here are the most relevant variables we focused on:\n",
        "\n",
        "Frequency and Type of Volunteering:\n",
        "PES16: Did the respondent spend any time volunteering for any organization in the past 12 months?\n",
        "PES16D: Frequency of volunteering (e.g., basically every day, a few times a week).\n",
        "PTS16E: Approximate hours spent volunteering.\n",
        "\n",
        "Political Engagement:\n",
        "PES2: How often the respondent discussed political, societal, or local issues with friends or family.\n",
        "PES5: How often these discussions occurred with neighbors.\n",
        "PES13: Contact or visits to a public official to express opinions.\n",
        "PES14: Boycotting or buying products based on political values or business practices.\n",
        "\n",
        "Civic Participation and Group Membership:\n",
        "PES15: Belonging to groups, organizations, or associations in the past 12 months.\n",
        "Neighbor and Community Interaction:\n",
        "PES7: Participation in activities to improve their neighborhood or community.\n",
        "Voting Behavior:\n",
        "PES11: Whether the respondent voted in the last local elections.\n",
        "\n",
        "Social Media and News Consumption:\n",
        "PES9: Posting views about political, societal, or local issues on the internet or social media.\n",
        "PES10: Frequency of consuming news related to political or societal issues.\n",
        "\n",
        "Basic Demographics:\n",
        "Age: PRTAGE (Person's age)\n",
        "Gender: PESEX (Sex of the respondent)\n",
        "Race/Ethnicity: PTDTRACE (Detailed race and Hispanic origin)\n",
        "Marital Status: PEMARITL (Marital status of the respondent)\n",
        "Household Composition: HRNUMHOU (Number of persons in the household)\n",
        "\n",
        "Potential Confounding Variables\n",
        "Income: HEFAMINC (Household family income level)\n",
        "Education: PEEDUCA (Highest level of school completed)\n",
        "Urban/Rural Status: GTMETSTA (Metropolitan or non-metropolitan status)\n",
        "Community Involvement: PES7 (Participation in neighborhood or community activities)\n",
        "Social Media Use: PES9 (Posting views about political, societal, or local issues on the internet or social media)\n"
      ],
      "id": "10f4d7e1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "vcl_supplement_raw.columns = vcl_supplement_raw.columns.str.lower()\n",
        "\n",
        "# I found out the data type is int64 for one df and object for the other\n",
        "\n",
        "cev_2021_raw = cev_2021_raw.astype(str)\n",
        "vcl_supplement_raw = vcl_supplement_raw.astype(str)\n",
        "\n",
        "# This finds all the variables in common between the two for a merge\n",
        "common_keys = list(set(vcl_supplement_raw.columns).intersection(\n",
        "    set(cev_2021_raw.columns)))\n",
        "\n",
        "\n",
        "cev_all_2021 = pd.merge(cev_2021_raw, vcl_supplement_raw,\n",
        "                        on=common_keys, how=\"outer\")\n",
        "\n",
        "cev_all_2021.head(5)\n",
        "\n",
        "# Note: Each row is a person- multiple people in the same household can have same household ID, so should not filter by unique\n",
        "\n",
        "# We can use a config.py file to keep this readable. Full details are in the config.py file"
      ],
      "id": "c7eff58d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from config import selected_variables, rename_mapping\n",
        "\n",
        "# selected_variables = ['hrhhid', 'hrhhid2', etc.]\n",
        "# This chooses the variables we want from the merged raw data\n",
        "\n",
        "# rename_mapping = \"hrhhid\": \"Household_ID\", \"hrhhid2\": \"Household_ID_2\", etc.\n",
        "# Renaming the variables for clarity\n",
        "\n",
        "\n",
        "cev_all_2021_filter = cev_all_2021[selected_variables].copy()\n",
        "#copy avoids potentially modifying original dataframe\n",
        "\n",
        "cev_all_2021_filter.rename(columns=rename_mapping, inplace=True)\n",
        "\n",
        "#Debugging: removing duplicate column(s)\n",
        "cev_all_2021_filter = cev_all_2021_filter.loc[:, ~cev_all_2021_filter.columns.duplicated()]"
      ],
      "id": "082bca9b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One data cleaning issue we encountered with the CEV/VCL data: the data is a mix of numeric code and qualitative input. We can create a mapping function to swap the numeric codes with qualitative input, but the existing qualitative input is outside of the data dictionary, so it won't get picked up by any mapping functions and will be transmuted into NaN data. We made a function that identifies all the values in the data that aren't picked up by our data dictionaries- this function is located in our config.py file.\n",
        "\n",
        "For example, if there are some entries in a column that are already coded \"Yes\" or \"No\" in addition to \"-1\", \"1\", \"2\", etc. our existing mapping won't account for them and will turn them into NANs. We want to catch those and account for them.\n"
      ],
      "id": "cbce2f0c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Attribution: Asked ChatGPT \"why isn't config.py updating when I add dictionaries to it; ChatGPT suggested using importlib reload\"\n",
        "# Import and reload config\n",
        "from pathlib import Path\n",
        "import os\n",
        "from us import states\n",
        "from config import add_engagement_score\n",
        "from config import *\n",
        "import importlib\n",
        "import config\n",
        "importlib.reload(config)\n",
        "\n",
        "\n",
        "# Replace FIPS codes with states\n",
        "\n",
        "fips_to_state = {int(state.fips): state.abbr for state in states.STATES}\n",
        "\n",
        "cev_all_2021_filter['US State'] = pd.to_numeric(\n",
        "    cev_all_2021_filter['US State'], errors='coerce')\n",
        "\n",
        "cev_all_2021_filter['US State'] = cev_all_2021_filter['US State'].map(\n",
        "    fips_to_state)\n",
        "\n",
        "# Replace \"Volunteered Past Year\" data (pes16)\n",
        "cev_all_2021_filter['Volunteered_Past_Year'] = cev_all_2021_filter['Volunteered_Past_Year'].map(\n",
        "    pes16_dict)\n",
        "\n",
        "# Replace \"Volunteering Frequency\" (pes16d)\n",
        "cev_all_2021_filter['Volunteering_Frequency'] = cev_all_2021_filter['Volunteering_Frequency'].map(\n",
        "    pes16d_dict)\n",
        "\n",
        "# Replace \"Hours Spent Volunteering\" (pts16e)\n",
        "cev_all_2021_filter['Hours_Spent_Volunteering'] = cev_all_2021_filter['Hours_Spent_Volunteering'].map(\n",
        "    pts16e_dict)\n",
        "\n",
        "# Replace \"Discussed Issues with Friends/Family\" data (pes2)\n",
        "cev_all_2021_filter['Discussed_Issues_With_Friends_Family'] = cev_all_2021_filter['Discussed_Issues_With_Friends_Family'].map(\n",
        "    pes2_dict)\n",
        "\n",
        "# Replace \"Discussed Issues with Neighbors\" data (pes5)\n",
        "cev_all_2021_filter['Discussed_Issues_With_Neighbors'] = cev_all_2021_filter['Discussed_Issues_With_Neighbors'].map(\n",
        "    pes5_dict)\n",
        "\n",
        "# Replace \"Contacted Public Official\" data (pes13)\n",
        "cev_all_2021_filter['Contacted_Public_Official'] = cev_all_2021_filter['Contacted_Public_Official'].map(\n",
        "    pes13_dict)\n",
        "\n",
        "# Replace \"Boycott Based on Values\" data (pes14)\n",
        "cev_all_2021_filter['Boycott_Based_On_Values'] = cev_all_2021_filter['Boycott_Based_On_Values'].map(\n",
        "    pes14_dict)\n",
        "\n",
        "# Replace \"Belonged to Groups\" data (pes15)\n",
        "cev_all_2021_filter['Belonged_To_Groups'] = cev_all_2021_filter['Belonged_To_Groups'].map(\n",
        "    pes15_dict)\n",
        "\n",
        "\n",
        "# Replace \"Community Improvement Activities\" data (pes7)\n",
        "cev_all_2021_filter['Community_Improvement_Activities'] = cev_all_2021_filter['Community_Improvement_Activities'].map(\n",
        "    pes7_dict)\n",
        "\n",
        "# Replace \"Voted in Local Election\" data (pes11)\n",
        "cev_all_2021_filter['Voted_In_Local_Election'] = cev_all_2021_filter['Voted_In_Local_Election'].map(\n",
        "    pes11_dict)\n",
        "\n",
        "# Replace \"Posted Views on Social Media\" data (pes9)\n",
        "cev_all_2021_filter['Posted_Views_On_Social_Media'] = cev_all_2021_filter['Posted_Views_On_Social_Media'].map(\n",
        "    pes9_dict)\n",
        "\n",
        "# Replace \"Frequency of News Consumption\" data (pes10)\n",
        "cev_all_2021_filter['Frequency_Of_News_Consumption'] = cev_all_2021_filter['Frequency_Of_News_Consumption'].map(\n",
        "    pes10_dict)\n",
        "\n",
        "# Replace \"Age\" data (prtage)\n",
        "cev_all_2021_filter['Age'] = cev_all_2021_filter['Age'].map(prtage_dict)\n",
        "\n",
        "# Replace \"Gender\" data (pesex)\n",
        "cev_all_2021_filter['Gender'] = cev_all_2021_filter['Gender'].map(pesex_dict)\n",
        "\n",
        "# Replace \"Race/Ethnicity\" data (ptdtrace)\n",
        "cev_all_2021_filter['Race_Ethnicity'] = cev_all_2021_filter['Race_Ethnicity'].map(\n",
        "    ptdtrace_dict)\n",
        "\n",
        "# Replace \"Marital Status\" data (pemaritl)\n",
        "cev_all_2021_filter['Marital_Status'] = cev_all_2021_filter['Marital_Status'].map(\n",
        "    pemaritl_dict)\n",
        "\n",
        "# Replace \"Household Size\" data (hrnumhou)\n",
        "cev_all_2021_filter['Household_Size'] = cev_all_2021_filter['Household_Size'].map(\n",
        "    hrnumhou_dict)\n",
        "\n",
        "# Replace \"Family Income Level\" data (hefaminc)\n",
        "cev_all_2021_filter['Family_Income_Level'] = cev_all_2021_filter['Family_Income_Level'].map(\n",
        "    hefaminc_dict)\n",
        "\n",
        "# Replace \"Education Level\" data (peeduca_dict)\n",
        "cev_all_2021_filter['Education_Level'] = cev_all_2021_filter['Education_Level'].map(\n",
        "    peeduca_dict)\n",
        "\n",
        "# Replace \"Urban Rural Status\" data (gtmetsta_dict)\n",
        "cev_all_2021_filter['Urban_Rural_Status'] = cev_all_2021_filter['Urban_Rural_Status'].map(\n",
        "    gtmetsta_dict)"
      ],
      "id": "9e0a02ea",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CEV/VCL Data - Measuring Political Engagement\n",
        "\n",
        "As part of our analysis, we gauged volunteerism by referring to the question “Did you volunteer in the last 12 months”? However, there isn’t a single “civic/political engagement” question in the CEV/VCL data, but rather several different questions that are related.\n",
        "We chose five of the most relevant questions and weighted each based on their level of effort:\n",
        "\n",
        "\n",
        "1. “How frequently do you talk to a family member/neighbor about politics?” (15%)\n",
        "2. “How frequently do you post political views on social media?” (15%)\n",
        "3. “How frequently do you consume political news/media?” (10%)\n",
        "4. “Did you contact an elected official to express your opinion in the last 12 months?” (30%) \n",
        "5. “Did you boycott a company based on their values in the last 12 months?” (30%)\n",
        "\n",
        "\n",
        "This generated a score from 0 - 100 that we could use as a (imperfect) proxy for political engagement. We mutated a new variable, political_engagement_score, to measure this and added it to our dataset.\n",
        "\n",
        "\n",
        "(Important caveat: For the political engagement questions, less than 20% of respondents answered three or more of the selected questions. To ensure meaningful data, we excluded all respondents who did not meet this threshold. While this approach improves the consistency of the dataset, we should be aware of potential selection bias.)\n",
        "\n",
        "# ANES data cleaning\n",
        "\n",
        "For the ANES data, we create\n"
      ],
      "id": "a4a6b701"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#list 1\n",
        "subset_list_1 = [column for column in polarization if \"V2010\" in column]\n",
        "\n",
        "#list 2\n",
        "subset_list_2 = [column for column in polarization if \"V2012\" in column]\n",
        "\n",
        "#put the lists together\n",
        "#make a loop \n",
        "\n",
        "#empty receiver\n",
        "subset_list = []\n",
        "\n",
        "#loop 1\n",
        "for value in subset_list_1:\n",
        "        subset_list.append(value)\n",
        "\n",
        "#loop 2\n",
        "for value in subset_list_2:\n",
        "        subset_list.append(value)                    \n",
        "\n",
        "#subset \n",
        "sub_polarization = polarization.filter(items= subset_list)\n",
        "\n",
        "#add a column that just equals 1 to use for tracking the number\n",
        "#of entries\n",
        "sub_polarization[\"Observations\"] = 1"
      ],
      "id": "985ca778",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "##Note: The below debugging code was suggested by ChatGPT to deal with some column value errors caused by political_engagement_score mutation. We weren't sure how to fix the errors without taking out the debugging code.\n",
        "\n",
        "# Debugging code - Before engagement score calculation\n",
        "print(\"Columns before adding engagement score:\")\n",
        "print(cev_all_2021_filter.columns.tolist())\n",
        "print(\"\\nShape before:\", cev_all_2021_filter.shape)\n",
        "\n",
        "\n",
        "# Mutate the engagement score variable we came up with in config.py\n",
        "cev_all_2021_filter = add_engagement_score(cev_all_2021_filter)\n",
        "\n",
        "# More debugging code\n",
        "print(\"\\nColumns after adding engagement score:\")\n",
        "print(cev_all_2021_filter.columns.tolist())\n",
        "print(\"\\nShape after:\", cev_all_2021_filter.shape)\n",
        "\n",
        "# Before saving\n",
        "print(\"\\nVerifying engagement score columns exist:\")\n",
        "print(\"'political_engagement_score' exists:\",\n",
        "      'political_engagement_score' in cev_all_2021_filter.columns)\n",
        "print(\"'engagement_level' exists:\",\n",
        "      'engagement_level' in cev_all_2021_filter.columns)"
      ],
      "id": "c356d2a1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#confirm this code exports the data into the 'data' folder into the repo\n",
        "\n",
        "\n",
        "# Lastly, export the cleaned data as a csv for plotting purposes\n",
        "shiny_data_path = Path(\"shiny-app/basic-app/data\")\n",
        "\n",
        "# Create directory if it doesn't exist\n",
        "shiny_data_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Save with explicit column list to ensure all columns are included (debugging)\n",
        "columns_to_save = cev_all_2021_filter.columns.tolist()\n",
        "cev_all_2021_filter.to_csv(\n",
        "    shiny_data_path / \"cev_2021_cleaned.csv\",\n",
        "    columns=columns_to_save,\n",
        "    index=False\n",
        ")\n",
        "\n",
        "# Verify saved file - more debugging\n",
        "verification_df = pd.read_csv(shiny_data_path / \"cev_2021_cleaned.csv\")\n",
        "print(\"\\nColumns in saved CSV:\")\n",
        "print(verification_df.columns.tolist())\n",
        "\n",
        "print(f\"Dataset saved to: {shiny_data_path / 'cev_2021_cleaned.csv'}\")"
      ],
      "id": "66df9c17",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Cleaning - ANES Data\n",
        "\n",
        "As with the CEV/VCL data, our goal was to subset the data so that it only contains relevant variables. We accomplish this by making two lists:\n",
        "\n",
        "List 1: This list is designed to capture variables covering geographic information (V201011, V201013a, V201013b, V201014a, V201014b)\n",
        "\n",
        "List 2: This list is designed to capture variables covering information about assessments of political positioning (i.e. left, right, center)"
      ],
      "id": "36e4aa9a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#list 1\n",
        "subset_list_1 = [column for column in polarization if \"V2010\" in column]\n",
        "\n",
        "#list 2\n",
        "subset_list_2 = [column for column in polarization if \"V2012\" in column]\n",
        "\n",
        "#put the lists together\n",
        "#make a loop \n",
        "\n",
        "#empty receiver\n",
        "subset_list = []\n",
        "\n",
        "#loop 1\n",
        "for value in subset_list_1:\n",
        "        subset_list.append(value)\n",
        "\n",
        "#loop 2\n",
        "for value in subset_list_2:\n",
        "        subset_list.append(value)                    \n",
        "\n",
        "#subset \n",
        "sub_polarization = polarization.filter(items= subset_list)\n",
        "\n",
        "#add a column that just equals 1 to use for tracking the number\n",
        "#of entries\n",
        "sub_polarization[\"Observations\"] = 1"
      ],
      "id": "6f30f31c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ANES - More Data Cleaning\n",
        "\n",
        "Analyzing Question V201200, which is a question asking:\n",
        "\n",
        "\"Where would you place yourself on this scale, or haven’t you\n",
        " thought much about this?\n",
        " Value Labels-9. Refused -8. Don’t know \n",
        "1. Extremely Liberal \n",
        "2. Liberal \n",
        "3. Slightly Liberal \n",
        "4. Moderate; middle of the road \n",
        "5. Slightly Conservative \n",
        "6. Conservative \n",
        "7. Extremely Conservative \n",
        "99. Haven’t thought much about this\"\n"
      ],
      "id": "155264d1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Make variables more clear\n",
        "\n",
        "crosswalk_polar = pd.DataFrame({\n",
        "    \"Self_Rating_(V201200)\":[-9, -8, 1, 2, 3, 4, 5, 6, 7, 99],\n",
        "    \"Ideology_(V201200)\": [\n",
        "        \"Refused\", \"Don't Know\", \"Extremely Liberal\",\n",
        "        \"Liberal\", \"Slightly Liberal\", \n",
        "        \"Moderate; middle of the road\",\n",
        "        \"Slightly Conservative\",\n",
        "        \"Conservative\",\n",
        "        \"Extremely Conservative\",\n",
        "        \"Haven’t thought much about this\"\n",
        "    ]\n",
        "    })\n",
        "\n",
        "#merge using crosswalk\n",
        "sub_polarization = sub_polarization.merge(crosswalk_polar, left_on = \"V201200\", right_on = \"Self_Rating_(V201200)\")"
      ],
      "id": "af2c8f2a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use this data to make a dataframe aggregated by state, and then we can show correlation between measure of polarity and the share of respondents in a state who did volunteer work.\n",
        "\n",
        " Note that we previously used two ANES variables as US State variables,  with only \"US State 2\" being used in analysis, purely because it has more in-universe entries. This appears to be partially due to respondent reactions to different questions, and partially due to information restrictions on the dataset. As such, \"US State\" is only used for CEV data. \n"
      ],
      "id": "9892e61f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Replace FIPS codes with states\n",
        "from us import states\n",
        "\n",
        "fips_to_state = {int(state.fips): state.abbr for state in states.STATES}\n",
        "\n",
        "sub_polarization[\"US State 2\"] = pd.to_numeric(sub_polarization['V201014b'], errors='coerce')\n",
        "\n",
        "sub_polarization['US State 2'] = sub_polarization['US State 2'].map(fips_to_state)\n"
      ],
      "id": "740e2222",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, make data using V201228, which asks:\n",
        "\n",
        "\"Generally speaking, do you usually think of yourself as [a\n",
        "Democrat, a Republican / a Republican, a Democrat], an\n",
        "independent, or what?\"\n",
        "\n",
        "-9. Refused\n",
        "-8. Don’t know\n",
        "-4. Technical error\n",
        "0. No preference {VOL - video/phone only}\n",
        "1. Democrat\n",
        "2. Republican\n",
        "3. Independent\n",
        "5. Other party {SPECIFY}\n"
      ],
      "id": "78816291"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "crosswalk_party_2 = pd.DataFrame({\n",
        "    \"Party_Numbers_(V201228)\":[-9, -8, -4, 0, 1, 2, 3, 5],\n",
        "    \"Party_Affiliation_(V201228)\":[\n",
        "        \"Refused\", \"Don't know\", \"Technical error\", \"No Preference\", \"Democrat\",\n",
        "        \"Republican\", \"Independent\", \"Other party\"\n",
        "        ]})\n",
        "\n",
        "sub_polarization = sub_polarization.merge(crosswalk_party_2, left_on = \"V201228\", right_on = \"Party_Numbers_(V201228)\")\n"
      ],
      "id": "01c7988d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Exploratory Analysis\n",
        "\n",
        "# 2a. Measures of Polarization\n",
        "\n",
        "We will use two measures of polarization from the ANES data; each provides some amount of information that can be interpreted to indicate polarization to a certain extent, though both have their drawbacks.\n",
        "\n",
        "1. Share of Outliers - we create a series of functions that group respondents by party Democrats with conservative-leaning ideologies, and Republicans with liberal-leaning ones. \n"
      ],
      "id": "2d356baf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def find_share(df, state):\n",
        "    \"\"\"\n",
        "    Processes a subset of survey data for a specific state to identify and count party-affiliated respondents and ideological outliers.\n",
        "\n",
        "    Returns a subset of the input DataFrame, including new columns for:\n",
        "        - 'Party_Count': Counts of individuals affiliated with major parties.\n",
        "        - 'Outliers': Counts of ideological outliers within each party.\n",
        "\"\"\"\n",
        "    #subset by state\n",
        "    sub = df[df[\"US State 2\"] == state]\n",
        "    Party_People = [\"Democrat\", \"Republican\"]\n",
        "    Conservatives = [\"Slightly conservative\",\n",
        "    \"Conservative\",\n",
        "    \"Extremely conservative\"]\n",
        "    Liberals = [\"Extremely Liberal\",\n",
        "    \"Liberal\", \"Slightly Liberal\"]\n",
        "    #count of partisans\n",
        "    Party_Count = []\n",
        "    #count of entries that are Dem but conservative or Repub but liberal\n",
        "    Outlier_box = []\n",
        "    #get Party_Count\n",
        "    for index, entry in sub.iterrows():\n",
        "            if entry[\"Party_Affiliation_(V201228)\"] in Party_People:\n",
        "                    Party_Count.append(1)\n",
        "            else:\n",
        "                    Party_Count.append(0)\n",
        "    \n",
        "    for index, entry in sub.iterrows():\n",
        "            if (entry[\"Ideology_(V201200)\"] in Conservatives) & (entry[\"Party_Affiliation_(V201228)\"] == \"Democratic\"):\n",
        "                    Outlier_box.append(1)\n",
        "            elif (entry[\"Ideology_(V201200)\"] in Liberals) & (entry[\"Party_Affiliation_(V201228)\"] == \"Republican\"):\n",
        "                    Outlier_box.append(1)\n",
        "            else:\n",
        "                    Outlier_box.append(0)\n",
        "    \n",
        "    sub[\"Party_Count\"] = Party_Count\n",
        "    sub[\"Outliers\"] = Outlier_box\n",
        "    return sub\n",
        "        \n",
        "Z = find_share(sub_polarization, \"IL\")                     \n",
        "\n",
        "IL_Group = Z.groupby(\"Party_Affiliation_(V201228)\")[[\"Outliers\", \"Party_Count\"]].sum().reset_index()\n",
        "\n",
        "IL_Group[\"Percent_Outliers\"] =  IL_Group[\"Outliers\"] / sum(IL_Group[\"Party_Count\"])\n"
      ],
      "id": "621d9324",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def seek_polar(df, state):\n",
        "    '''\n",
        "    Aggregates polarization data for a specific state, calculating the share of ideological outliers within party-affiliated populations.\n",
        "\n",
        "    '''\n",
        "    mod_df = find_share(df, state)\n",
        "    mod_df = mod_df.groupby(\n",
        "        \"Party_Affiliation_(V201228)\"\n",
        "        )[[\"Outliers\", \"Party_Count\"]].sum().reset_index()\n",
        "\n",
        "    mod_df[\"Percent_Outliers\"] =  mod_df[\"Outliers\"] / sum(mod_df[\"Party_Count\"])\n",
        "    return mod_df\n",
        "\n",
        "#Example with IL\n",
        "seek_polar(sub_polarization, \"IL\")\n"
      ],
      "id": "fd6a6fc2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def find_share_state(df, state):\n",
        "    '''\n",
        "    Generates a modified subset of survey data for a given state, identifying partisans and ideological outliers.\n",
        "'''\n",
        "    #subset by state\n",
        "    sub = df[df[\"US State 2\"] == state]\n",
        "    Party_People = [\"Democrat\", \"Republican\"]\n",
        "    Conservatives = [\"Slightly Conservative\",\n",
        "    \"Conservative\",\n",
        "    \"Extremely Conservative\"]\n",
        "    Liberals = [\"Extremely Liberal\",\n",
        "    \"Liberal\", \"Slightly Liberal\"]\n",
        "    #count of partisans\n",
        "    Party_Count = []\n",
        "    #count of entries that are Dem but conservative or Repub but liberal\n",
        "    Outlier_box = []\n",
        "    #get Party_Count\n",
        "    for index, entry in sub.iterrows():\n",
        "            if entry[\"Party_Affiliation_(V201228)\"] in Party_People:\n",
        "                    Party_Count.append(1)\n",
        "            else:\n",
        "                    Party_Count.append(0)\n",
        "    \n",
        "    for index, entry in sub.iterrows():\n",
        "            if (entry[\"Ideology_(V201200)\"] in Conservatives) & (entry[\"Party_Affiliation_(V201228)\"] == \"Democratic\"):\n",
        "                    Outlier_box.append(1)\n",
        "            elif (entry[\"Ideology_(V201200)\"] in Liberals) & (entry[\"Party_Affiliation_(V201228)\"] == \"Republican\"):\n",
        "                    Outlier_box.append(1)\n",
        "            else:\n",
        "                    Outlier_box.append(0)\n",
        "    \n",
        "    sub[\"Party_Count\"] = Party_Count\n",
        "    sub[\"Outliers\"] = Outlier_box\n",
        "    return sub\n"
      ],
      "id": "30b9cd9b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def find_share_nation(df):\n",
        "    '''\n",
        "    Processes survey data at the national level to identify party-affiliated respondents and ideological outliers.\n",
        "'''\n",
        "    Party_People = [\"Democrat\", \"Republican\"]\n",
        "    Conservatives = [\"Slightly Conservative\",\n",
        "    \"Conservative\",\n",
        "    \"Extremely Conservative\"]\n",
        "    Liberals = [\"Extremely Liberal\",\n",
        "    \"Liberal\", \"Slightly Liberal\"]\n",
        "    #count of partisans\n",
        "    Party_Count = []\n",
        "    #count of entries that are Dem but conservative or Repub but liberal\n",
        "    Outlier_box = []\n",
        "    #get Party_Count\n",
        "    for index, entry in df.iterrows():\n",
        "            if entry[\"Party_Affiliation_(V201228)\"] in Party_People:\n",
        "                    Party_Count.append(1)\n",
        "            else:\n",
        "                    Party_Count.append(0)\n",
        "    #get outlier count\n",
        "    for index, entry in df.iterrows():\n",
        "            if (entry[\"Ideology_(V201200)\"] in Conservatives) & (entry[\"Party_Affiliation_(V201228)\"] == \"Democratic\"):\n",
        "                    Outlier_box.append(1)\n",
        "            elif (entry[\"Ideology_(V201200)\"] in Liberals) & (entry[\"Party_Affiliation_(V201228)\"] == \"Republican\"):\n",
        "                    Outlier_box.append(1)\n",
        "            else:\n",
        "                    Outlier_box.append(0)\n",
        "    \n",
        "    df[\"Party_Count\"] = Party_Count\n",
        "    df[\"Outliers\"] = Outlier_box\n",
        "    return df"
      ],
      "id": "2ee9a9d5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def polar_table(df):\n",
        "    '''\n",
        "    Generates a summary table of polarization data, grouping by state to calculate the share of ideological outliers.\n",
        "    '''\n",
        "    mod_df = find_share_nation(df)\n",
        "    #make a grouped df that takes sum of each states' outliers and \n",
        "    #people who identify with a party\n",
        "    mod_df = mod_df.groupby(\"US State 2\")[\n",
        "        [\"Outliers\", \"Party_Count\"]\n",
        "        ].sum().reset_index()\n",
        "    mod_df[\"Percent_Outliers\"] =  mod_df[\"Outliers\"] / sum(mod_df[\"Party_Count\"])\n",
        "    return mod_df\n"
      ],
      "id": "3a7c8050",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "polar_by_party = polar_table(sub_polarization)\n",
        "\n",
        "#graphing percentages\n",
        "percent_graph_outliers = alt.Chart(polar_by_party).mark_bar().encode(\n",
        "    alt.X(\"US State 2\", title = \"State\"),\n",
        "    alt.Y(\"Percent_Outliers\", title = \"Outlier Share\"),\n",
        "    alt.Color(\"US State 2\")\n",
        ")\n",
        "\n",
        "#graphing sums\n",
        "sum_graph_outliers = alt.Chart(polar_by_party).mark_bar().encode(\n",
        "    alt.X(\"US State 2\", title = \"State\"),\n",
        "    alt.Y(\"Outliers\", title = \"Outlier Sum\"),\n",
        "    alt.Color(\"US State 2\")\n",
        ")"
      ],
      "id": "418b9e8d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In a paper on quantifying polarization written by Aaron Bramson et al (https://inferenceproject.yale.edu/sites/default/files/688938.pdf), the authors examine a range of polarization indicators. A relatively simple (and in some ways problematic) measurement is called spread, or dispersion- essentially the gap between the most extreme political positions.\n",
        "\n",
        "In the paper, Bramson et al. explain: \"Polarization in the sense of spread can be measured as the value of the agent with the highest belief value minus the value of the agent with the lowest belief value (sometimes called the ‘range’ of the data).\"\"\n",
        "\n",
        "We (imperfectly) approximate this using two more variables: V201206 and V201207. These ask respondents to position political parties on the political spectrum. We can select the most ideologically distant nodes on the personal ideology scale (extremely liberal and extremely conservative) and capture how far apart their conceptions of each party are,  on average, and then disaggregate by state.\n",
        "\n",
        "We will assign the different ideological positions to different points on a spectrum, namely:\n",
        "-3, -2, and -1 are \"Extremely Liberal\", \n",
        "\"Liberal\",  and \"Slightly Liberal\"; \n",
        "\n",
        "and:\n",
        "0 is \"Moderate; middle of the road\"; \n",
        "\n",
        "finally,\n",
        "1, 2, and 3 are \"Slightly conservative\",\n",
        "\"Conservative\" and \"Extremely conservative.\"\"\n",
        "\n",
        "We'll then compare average positions by state. For example, if the average \n",
        "extremely liberal respondent in Texas places Democrats at at -1 (slightly liberal) and the average for the extremely conservative respondents in -3 (extremely liberal), then the distance between the two is 4, meaning Texas would have a spread of 4 for this question.\n",
        "\n",
        "We create the crosswalks V201206 and V201207 -"
      ],
      "id": "ba112737"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "crosswalk_V201206 = pd.DataFrame({\n",
        "    #the dataset's scaled\n",
        "    \"Dem_Num_(V201206)\":[-9, -8, 1, 2, 3, 4, 5, 6, 7],\n",
        "    #the dataset's ideology\n",
        "    \"Dem_Ideology_(V201206)\": [\n",
        "        \"Refused\", \"Don't Know\", \"Extremely Liberal\",\n",
        "        \"Liberal\", \"Slightly Liberal\", \n",
        "        \"Moderate; middle of the road\",\n",
        "        \"Slightly Conservative\",\n",
        "        \"Conservative\",\n",
        "        \"Extremely Conservative\"\n",
        "    ],\n",
        "    #new values for comparison\n",
        "    \"Dem_Positioning(V201206)\":[0, 0, -3, -2, -1, 0, 1, 2, 3]\n",
        "    })\n",
        "\n",
        "#They're exactly the same\n",
        "crosswalk_V201207 = pd.DataFrame({\n",
        "    #the dataset's scale\n",
        "    \"Repub_Num_(V201207)\":[-9, -8, 1, 2, 3, 4, 5, 6, 7],\n",
        "    #the dataset's ideology\n",
        "    \"Repub_Ideology_(V201207)\": [\n",
        "        \"Refused\", \"Don't Know\", \"Extremely Liberal\",\n",
        "        \"Liberal\", \"Slightly Liberal\", \n",
        "        \"Moderate; middle of the road\",\n",
        "        \"Slightly Conservative\",\n",
        "        \"Conservative\",\n",
        "        \"Extremely Conservative\"\n",
        "    ],\n",
        "    #new values for comparison\n",
        "    \"Repub_Positioning(V201207)\":[0, 0, -3, -2, -1, 0, 1, 2, 3]\n",
        "    })\n",
        "\n",
        "#crosswalking V201206\n",
        "sub_polarization = sub_polarization.merge(crosswalk_V201206, left_on = \"V201206\", right_on = \"Dem_Num_(V201206)\")\n",
        "\n",
        "#crosswalking V201207\n",
        "sub_polarization = sub_polarization.merge(crosswalk_V201207, left_on = \"V201207\", right_on = \"Repub_Num_(V201207)\")\n",
        "\n",
        "#drop Dem_Num and Repub_Num for clarity (we'll be using the reassigned numbers)\n",
        "sub_polarization = sub_polarization.drop([\"Dem_Num_(V201206)\", \"Repub_Num_(V201207)\"], axis = 1)"
      ],
      "id": "c1abded1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use the Positioning columns to compare the average party position \n",
        "selections between the 2 extremes. \n",
        "\n",
        "Step 1: First grouping"
      ],
      "id": "a575098a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#filter out all self-identifiers that aren't \"Extremely Liberal\"\n",
        "#or Extremely Conservative\n",
        "ex_polarization = sub_polarization[\n",
        "    (sub_polarization[\"Ideology_(V201200)\"] == \"Extremely Conservative\") | \n",
        "    (sub_polarization[\"Ideology_(V201200)\"] == \"Extremely Liberal\")\n",
        "    ]\n",
        "\n",
        "#filter out entries of Party Ideology Position that are \"Don't Know\" and \"Refused\"\n",
        "ex_polarization = ex_polarization[\n",
        "    (sub_polarization[\"Dem_Ideology_(V201206)\"] != \"Don't Know\") &\n",
        "    (sub_polarization[\"Dem_Ideology_(V201206)\"] != \"Refused\") &\n",
        "    (sub_polarization[\"Repub_Ideology_(V201207)\"] != \"Don't Know\") &\n",
        "    (sub_polarization[\"Repub_Ideology_(V201207)\"] != \"Refused\") \n",
        "    ]\n",
        "\n",
        "\n",
        "#make column for Liberal (i.e. Left tail) and Conservative (i.e. Right tail) \n",
        "Extreme_L_C = [\n",
        "    \"Liberal\" if row[\"Ideology_(V201200)\"] == \"Extremely Liberal\" else \"Conservative\" \n",
        "    for index, row in ex_polarization.iterrows()\n",
        "    ]\n",
        "\n",
        "#save to dataframe\n",
        "ex_polarization[\"Extreme_Position\"] = Extreme_L_C\n",
        "\n",
        "#groupby Extreme_Position and US State 2 and get average Dem and Repub positioning. Then save this to a df called position_groups\n",
        "position_groups = ex_polarization.groupby([\"US State 2\", \"Extreme_Position\"])[[\"Dem_Positioning(V201206)\", \"Repub_Positioning(V201207)\"]].mean().reset_index()"
      ],
      "id": "31a70d04",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 2: We use the variable position_groups to create a dataframe that has 4 columns:\n",
        "(1) The position Liberals give Democrats on the spectrum\n",
        "(2) the position Conservatives give Democrats on the spectrum\n",
        "(3) the position Liberals give Republicans on the spectrum\n",
        "(4) the position Conservatives give Republicans on the spectrum\n"
      ],
      "id": "dd1acad4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Attribution: Asked ChatGPT for help fixing my list comprehension. Also asked ChatGPT how to flatten a multi-index column, which recommended ##source: https://www.w3resource.com/pandas/dataframe/dataframe-pivot.php\n",
        "\n",
        "\n",
        "#pivot on Extreme_Position\n",
        "pivot_position = position_groups.pivot(\n",
        "    index = \"US State 2\", \n",
        "    columns = \"Extreme_Position\", \n",
        "    values = [\"Dem_Positioning(V201206)\", \"Repub_Positioning(V201207)\"]\n",
        "    )\n",
        "\n",
        "#reset index to retrieve US State 2 variable from index\n",
        "pivot_position = pivot_position.reset_index()\n",
        "\n",
        "#Flatten multi-index by joining the upper and lower\n",
        "#levels of the multi-indexed columns together\n",
        "pivot_position.columns = ['_'.join(col).strip() for col in pivot_position.columns.values]\n",
        "\n",
        "#rename flattened columns\n",
        "pivot_position = pivot_position.rename(\n",
        "        columns = {\n",
        "            \"US State 2_\":\"US State 2\", \n",
        "            \"Dem_Positioning(V201206)_Conservative\":\"Dem_Position_C\",\n",
        "            \"Dem_Positioning(V201206)_Liberal\":\"Dem_Position_L\",\n",
        "            \"Repub_Positioning(V201207)_Conservative\":\"Repub_Position_C\",\n",
        "            \"Repub_Positioning(V201207)_Liberal\":\"Repub_Position_L\"\n",
        "        }\n",
        "    )\n"
      ],
      "id": "66e8148e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 3: Now, we use those 4 columns to create the spread, meaning the absolute value of the difference betweeen:\n",
        "\n",
        "(1) The position Liberals give Democrats on the spectrum and the position Conservatives give Democrats on the spectrum\n",
        "\n",
        "(2) The position Liberals give Republicans on the spectrum and the position Conservatives give Republicans on the spectrum\n"
      ],
      "id": "5ecfdb96"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Attribution: Used this article: https://www.w3resource.com/pandas/dataframe/dataframe-pivot.php\n",
        "#Asked ChatGPT how to flatten a multi-index column\n",
        "\n",
        "#capture spread variables\n",
        "pivot_position[\"Spread_Dem\"] = abs(\n",
        "    pivot_position[\"Dem_Position_C\"] - \n",
        "    pivot_position[\"Dem_Position_L\"]\n",
        "    )\n",
        "\n",
        "pivot_position[\"Spread_Repub\"] = abs(\n",
        "    pivot_position[\"Repub_Position_C\"] - \n",
        "    pivot_position[\"Repub_Position_L\"]\n",
        "    )"
      ],
      "id": "8cee1ef2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 4: Now, we graph those differences and interpret these spreads as an indicator of polarization. We acknowledge that this is too simple an analysis to account for the full complexity of this kind of measurement, as polarization involves not just distance between extremes, but also clustering around them. We also acknowledge that our political scale assumes a linear ideological spectrum, which isn't always the case.\n"
      ],
      "id": "1679c3b4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Opinion on the position of the Democratic Party\n",
        "Democratic_Party_Spread_Graph = alt.Chart(pivot_position).mark_bar().encode(\n",
        "    alt.X(\"US State 2\", title = \"State\"),\n",
        "    alt.Y(\"Spread_Dem\", \n",
        "    title = \"Spread of Views\"),\n",
        "    alt.Color(\"US State 2\")\n",
        ").properties(title = alt.TitleParams(\"Spread of Views on Democratic Party Ideological Position\"))\n",
        "\n",
        "#Opinion on the position of the Republican Party\n",
        "Republican_Party_Spread_Graph = alt.Chart(pivot_position).mark_bar().encode(\n",
        "    alt.X(\"US State 2\", title = \"State\"),\n",
        "    alt.Y(\"Spread_Repub\", \n",
        "    title = \"Spread of Views\"),\n",
        "    alt.Color(\"US State 2\")\n",
        ").properties(title = alt.TitleParams(\"Spread of Views on Republican Party Ideological Position\"))"
      ],
      "id": "bdd4d8c0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 5: We merge the two datasets together on \"US State 2\". Note that this merged dataset could be misleading, because some of the merged variables only apply to the \"extreme\" respondents in each state, and so it's not representative of the entire state's respondents' positioning of different parties. We've dropped those variables from the merge to try to account for this.\n"
      ],
      "id": "3a882788"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "merged_polarization = sub_polarization.merge(pivot_position, left_on = \"US State 2\", right_on = \"US State 2\", how = \"outer\")\n",
        "\n",
        "#drop variables that don't make sense when merged\n",
        "merged_polarization = merged_polarization.drop([\n",
        "    \"Dem_Position_C\", \"Dem_Position_L\",\n",
        "    \"Repub_Position_C\", \"Repub_Position_L\"], \n",
        "    axis = 1\n",
        "    )"
      ],
      "id": "b961496e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 6: We merge the AmeriCorps CEV/VCL data with the spread data so far\n"
      ],
      "id": "d6cd407d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#remove 'Not in Universe', 'No Answer', 'Refused'\n",
        "#from cev_all_2021_filter\n",
        "\n",
        "Non_Number_List = [\n",
        "    'Not in Universe', np.nan, \"Do Not Know\",\n",
        "    'No Answer', 'Refused']\n",
        "\n",
        "cev_all_2021_all_number = cev_all_2021_filter[\n",
        "    ~cev_all_2021_filter[\"Hours_Spent_Volunteering\"].isin(Non_Number_List)\n",
        "    ]\n",
        "\n",
        "#group volunteer rates by state\n",
        "group_cev = cev_all_2021_all_number.groupby(\n",
        "    \"US State\"\n",
        "    )[[\"Hours_Spent_Volunteering\", \n",
        "    \"political_engagement_score\"]].mean().reset_index()\n",
        "\n",
        "main_group = group_cev.merge(\n",
        "    pivot_position, left_on = \"US State\", right_on = \"US State 2\"\n",
        ")"
      ],
      "id": "8bb10ff9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 7: We create a function for viewing Political Engagement alongside spread, one generating a table with 2 states for comparison, and another 2 \n",
        "returning graphs\n"
      ],
      "id": "6583c05c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#return table\n",
        "def engagement_spread_table(df, state_1, state_2):\n",
        "        sub = df[\n",
        "            (df[\"US State\"] == state_1) |\n",
        "            (df[\"US State\"] == state_2)]\n",
        "        sub = sub.filter([\"US State\", \"political_engagement_score\", \"Spread_Dem\", \"Spread_Repub\"])\n",
        "        return sub\n",
        "\n",
        "#return graph with Democratic positioning \n",
        "def engagement_spread_graph_D(df, column):\n",
        "        graph = alt.Chart(df).mark_bar().encode(\n",
        "        alt.X(\"US State 2\", title = \"State\", sort = \"-y\"),\n",
        "        alt.Y(\"Spread_Dem\", title = \"Spread of Extreme Views\"),\n",
        "         alt.Color(\n",
        "            column, \n",
        "            scale = alt.Scale(range = [\"lightblue\", \"darkblue\"])\n",
        "            )\n",
        "        ).properties(\n",
        "            title = alt.TitleParams(\n",
        "                \"Spread of Views on Democratic Party Ideological Position\"\n",
        "                )\n",
        "            )\n",
        "        return graph\n",
        "\n",
        "#return graph with Republican positioning \n",
        "def engagement_spread_graph_R(df, column):    \n",
        "        graph = alt.Chart(df).mark_bar().encode(\n",
        "        alt.X(\"US State 2\", title = \"State\", sort = \"-y\"),\n",
        "        alt.Y(\"Spread_Repub\", title = \"Spread of Extreme Views\"),\n",
        "        alt.Color(\n",
        "            column, \n",
        "            scale = alt.Scale(range = [\"lightblue\", \"darkblue\"]),\n",
        "            )\n",
        "        ).properties(\n",
        "            title = alt.TitleParams(\n",
        "                \"Spread of Views on Republican Party Ideological Position\"\n",
        "                )\n",
        "            )\n",
        "        return graph"
      ],
      "id": "d1f3c9f9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below is an example of using our function to generate a political engagement score for different states: \n"
      ],
      "id": "ce958366"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#sample static table with \n",
        "Sample_Table = engagement_spread_table(main_group, \"IL\", \"OR\")\n",
        "\n",
        "print(Sample_Table)"
      ],
      "id": "cc3d5f18",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And below are sample static graphs on Democratic and Republican positions:"
      ],
      "id": "2794de21"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#using average political engagement\n",
        "Dem_Graph_Spread_1 = engagement_spread_graph_D(main_group, \"political_engagement_score\")\n",
        "\n",
        "#using average volunteer hours\n",
        "Dem_Graph_Spread_2 = engagement_spread_graph_D(main_group, \"Hours_Spent_Volunteering\")\n",
        "\n",
        "Dem_Graph_Spread_1.show()\n",
        "\n",
        "Dem_Graph_Spread_2.show()"
      ],
      "id": "b89636e7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#using average political engagement\n",
        "Repub_Graph_Spread_1 = engagement_spread_graph_R(main_group, \"political_engagement_score\")\n",
        "\n",
        "#using average volunteer hours\n",
        "Repub_Graph_Spread_2 = engagement_spread_graph_R(main_group, \"Hours_Spent_Volunteering\")\n",
        "\n",
        "Repub_Graph_Spread_1.show() \n",
        "\n",
        "Repub_Graph_Spread_2.show()"
      ],
      "id": "968748cf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below is a atatic graph of ideological position in the US nationally as of 2020:\n"
      ],
      "id": "2a2e5575"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "alt.data_transformers.enable(\"vegafusion\")\n",
        "#create list for graph to sort on \n",
        "sorting_list = [\n",
        "        \"Refused\", \"Don't Know\", \"Extremely Liberal\",\n",
        "        \"Liberal\", \"Slightly Liberal\", \n",
        "        \"Moderate; middle of the road\",\n",
        "        \"Slightly Conservative\",\n",
        "        \"Conservative\",\n",
        "        \"Extremely Conservative\",\n",
        "        \"Haven’t thought much about this\"\n",
        "    ]\n",
        "\n",
        "#filter out non-responses\n",
        "global_non_response_list = [\n",
        "    \"Haven’t thought much about this\",\n",
        "    \"Refused\", \"Don't Know\"\n",
        "    ]\n",
        "\n",
        "local_filter = sub_polarization[\n",
        "    ~sub_polarization[\"Ideology_(V201200)\"].isin(global_non_response_list)\n",
        "]\n",
        "\n",
        "Ideological_Position_US = alt.Chart(local_filter).mark_bar().encode(\n",
        "    alt.X(\n",
        "        \"Ideology_(V201200):N\", \n",
        "        title = \"Ideological Position\",\n",
        "        sort = sorting_list),\n",
        "    alt.Y(\"Observations\", title = \"Number of Respondents\"),\n",
        "    alt.Color(\"Ideology_(V201200)\", sort = sorting_list)\n",
        ").properties(title = alt.TitleParams(\n",
        "            f\"Ideological Position in the U.S.\"\n",
        "        ))\n",
        "\n",
        "Ideological_Position_US.show()"
      ],
      "id": "63876731",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: We removed non-responses, likely creating a bias in the relative\n",
        "size of the remaining groups (it's difficult to predict the direction\n",
        "of said bias, however.)\n",
        "\n",
        "Additionally, below is a sample static graph of ideological position by state, using IL as an example:\n"
      ],
      "id": "4cdcc862"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def ideology_by_state(df, state):\n",
        "        #filter out non-responses\n",
        "        non_response_list = [\n",
        "            \"Haven’t thought much about this\", \n",
        "            \"Refused\", \"Don't Know\"\n",
        "            ]\n",
        "        sub = df[\n",
        "            ~df[\"Ideology_(V201200)\"].isin(non_response_list)\n",
        "            ]\n",
        "        #filter for the selected state\n",
        "        sub = sub[sub[\"US State 2\"] == state]\n",
        "        #create list for graph to sort on \n",
        "        sorting_list = [\n",
        "        \"Extremely Liberal\",\n",
        "        \"Liberal\", \"Slightly Liberal\", \n",
        "        \"Moderate; middle of the road\",\n",
        "        \"Slightly Conservative\",\n",
        "        \"Conservative\",\n",
        "        \"Extremely Conservative\"\n",
        "        ]\n",
        "        graph = alt.Chart(sub).mark_bar().encode(\n",
        "            alt.X(\n",
        "                \"Ideology_(V201200):N\", \n",
        "                title = \"Ideological Position\",\n",
        "                sort = sorting_list\n",
        "                ),\n",
        "            alt.Y(\"count():Q\", title = \"Number of Respondents\"),\n",
        "            alt.Color(\"Ideology_(V201200):N\", sort = sorting_list)\n",
        "        ).properties(title = alt.TitleParams(\n",
        "            f\"Ideological Position in {state}\"\n",
        "        ))\n",
        "        return graph\n",
        "\n",
        "#Example for Illinois\n",
        "Ideological_Position_IL = ideology_by_state(sub_polarization, \"IL\")\n",
        "\n",
        "Ideological_Position_IL.show()"
      ],
      "id": "5f4ff6a7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lastly, we will use the merged AmeriCorps and ANES data to plot a correlation between volunteer hours and political engagement:\n"
      ],
      "id": "cc88d8ae"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Correlation_Graph = alt.Chart(main_group).mark_circle().encode(\n",
        "    alt.X(\"Hours_Spent_Volunteering\", title=\"Average Volunteer Hours\"),\n",
        "    alt.Y(\"political_engagement_score\", title=\"Average Political Engagement Score\").scale(\n",
        "        domain=(\n",
        "            main_group[\"political_engagement_score\"].min() - 3,\n",
        "            main_group[\"political_engagement_score\"].max() + 3\n",
        "        )\n",
        "    ),\n",
        "    alt.Color(\"US State 2\")\n",
        ").properties(title=alt.TitleParams(\n",
        "    \"Correlation between volunteer hours and political engagement\"\n",
        "))\n",
        "\n",
        "Correlation_Graph.show()"
      ],
      "id": "588a7fed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This shows a noted positive correlation between volunteer hours and political engagement. However, as we'll see, this doesn't necessarily imply that increasing volunteering will lead to higher civic engagement.\n",
        "\n",
        "4. Reproductibility (10%)\n",
        "    * The project and files should be structured and documented so that the TAs can clone your repository and reproduce your results (see \"Final Repository\" below) by knitting your `.qmd` and, if needed, downloading the dataset(s) you use using the link provided in the `.qmd` comments\n",
        "5. Git (10%)\n",
        "    * You should submit your project as a Git repository.\n",
        "    * Create multiple branches as you work for different pieces of the analysis. Branches may correspond to work done by different partners or to different features if you are working alone.\n",
        "    * Your final repository should have one branch: `main`\n",
        "    * We reserve the right to check the git commit history to ensure that all members have contributed to the project.\n",
        "6. Extra credit: text processing (up to 10%)\n",
        "    * Introduce some form of text analysis using natural language processing methods discussed in class.\n",
        "\n",
        "## Writeup (15%)\n",
        "* You will then spend *no more than 3 pages* writing up your project. \n",
        "* The primary purpose of this writeup is to inform us of what we are reading before we look at your code.\n",
        "* You should describe your research question, then discuss the approach you took and the coding involved, including discussing any weaknesses or difficulties encountered. \n",
        "* Display your static plots, and briefly describe them and your Shiny app. Discuss the policy implications of your findings.\n",
        "* Finish with a discussion of directions for future work. \n",
        "* The top of your writeup should include the names of all group members, their respective sections, and Github user names.\n",
        "\n",
        "## Presentation (15%)\n",
        "* On the day of the presentation, one of the group members will be *randomly selected* to give a *8-minute in-class presentation*. All group members must be present.\n",
        "* Any group member who is not present will receive an automatic 0 for the presentation portion of the final project.\n",
        "* The presentation will be of slides that largely mirror the structure of the writeup, but will be more focused on discussing the research question and results as opposed to explaining the details of the coding. \n",
        "\n",
        "# Final Repository\n",
        "Your final repository must contain the following:\n",
        "\n",
        "* Documentation and Meta-data\n",
        "    * A `requirements.txt` file \n",
        "    * A `.gitignore` file that ignores unneeded files (e.g. `venv`) \n",
        "* Writeup: a user should be able to knit your `.qmd` file and re-generate the HTML version of your writeup\n",
        "    * The `.qmd` file associated with your write-up\n",
        "    * An HTML and PDF'd version of your writeup\n",
        "    * A folder named `pictures` that contains the files for any pictures required to knit your writeup\n",
        "* Data\n",
        "    * A folder named `data` that contains the initial, unmodified dataframes you download and the final versions of the dataframe(s) you built.\n",
        "    * If the dataset is greater than 100MB, it can hosted on Drive or Dropbox and the link should be provided in your .`qmd` file as a comment\n",
        "* Shiny app\n",
        "    * A folder named `shiny-app` that contains the code and any additional files needed to deploy your app\n",
        "    * A user should be able to deploy your app directly from the command line within this folder\n",
        "\n",
        "\n",
        "# Key Dates\n",
        "* By November 1\n",
        "    * Proposal submitted to Canvas quiz\n",
        "    * (Optional) meeting with Professor Ganong, Professor Shi, or Head TA Ozzy Houck\n",
        "    * Sign up for presentation slot\n",
        "* December 2- December 5: in-class presentations\n",
        "* December 7, 5PM: final repository submitted via Gradescope"
      ],
      "id": "db1c6b7e"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "pset5_env",
      "language": "python",
      "display_name": "Python (pset5_env)",
      "path": "/Users/charleshuang/Library/Jupyter/kernels/pset5_env"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}